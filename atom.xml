<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Commit Logs</title>
  
  <subtitle>Lei Gong</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.commitlogs.com/"/>
  <updated>2017-12-16T20:25:06.000Z</updated>
  <id>https://www.commitlogs.com/</id>
  
  <author>
    <name>Lei Gong</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Seedfinder - Infrastructure to Improve Sample Balance for Online A/B tests</title>
    <link href="https://www.commitlogs.com/2017/12/15/seedfinder-infrastructure-improve-sample-balance-online-ab-tests/"/>
    <id>https://www.commitlogs.com/2017/12/15/seedfinder-infrastructure-improve-sample-balance-online-ab-tests/</id>
    <published>2017-12-16T06:39:48.000Z</published>
    <updated>2017-12-16T20:25:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>(This blog post was originally published at <a href="https://www.thumbtack.com/engineering/seedfinder-infrastructure-improve-sample-balance-online-b-tests/" target="_blank" rel="noopener">Thumbtack Engineering</a>.)</p><p>Thumbtack helps customers tackle their to-do list by connecting local professionals with the right customers all across the nation. Our teams are focused on building out this two-sided marketplace and creating the tools to enable pros to manage and scale their business.</p><p>When it comes to building products, Thumbtack takes a data-driven approach that relies heavily on experimentation and iteration. At any given point in time, we’re running dozens of A/B tests that touch multiple features and product flows.</p><p>However designing A/B tests correctly is not always simple, given the marketplace nature of our platform and the breadth of categories we support. In this blog post, we’ll discuss some of the challenges in setting up A/B tests and explore the evolution of Seedfinder, the infrastructure we built to allow our data scientists to sleep more soundly.</p><h2 id="The-Challenges"><a href="#The-Challenges" class="headerlink" title="The Challenges"></a>The Challenges</h2><h3 id="Pre-Experiment-Imbalance"><a href="#Pre-Experiment-Imbalance" class="headerlink" title="Pre Experiment Imbalance"></a>Pre Experiment Imbalance</h3><p>One major challenge in designing an A/B test is accounting for inherent imbalances between test buckets. In one instance, we performed an A/A test comparing the same version of landing pages in different markets and saw a 5% lift in metrics for the treatment vs. baseline bucket. Pre-experiment imbalance affects our ability to draw reliable conclusions from experiment results.</p><p>This issue can be mitigated through repeated randomization of A/A tests to find a seed that balances metrics adequately across experiment buckets. More info can be found <a href="https://www.thumbtack.com/engineering/repeated-rerandomization/" target="_blank" rel="noopener">in this blog post</a>, including all the statistics behind this approach.</p><h3 id="Limited-Data-Scientist-Resources"><a href="#Limited-Data-Scientist-Resources" class="headerlink" title="Limited Data Scientist Resources"></a>Limited Data Scientist Resources</h3><p>Initially, our data scientists manually ran R/Python scripts to account for pre-experiment imbalance. These scripts required a lot of attention and took several hours to run. While this ad hoc approach allowed us to run certain experiments, this process clearly would not scale as the number of experiments increased.</p><h3 id="Custom-Experiment-Population"><a href="#Custom-Experiment-Population" class="headerlink" title="Custom Experiment Population"></a>Custom Experiment Population</h3><p>As Thumbtack continues to grow, so does the complexity of experiments. There is an increasing number of experiments that target a specific subset of users. Instead of placing an additional burden on data scientists, we want to enable developers to easily describe the population to experiment on.</p><h2 id="The-Infrastructure"><a href="#The-Infrastructure" class="headerlink" title="The Infrastructure"></a>The Infrastructure</h2><p>In order to keep up with the increasing demand for experiments, we built a self-serve automated system for setting up experiments. Here’s how our infrastructure evolved over time.</p><p>As part of the service-oriented architecture migration efforts, experiment assignment logic was broken out to its own service.</p><p><img src="/images/seedfinder_1.jpg" alt=""></p><p>To start a new experiment, developers can commit a configuration file to a git repo which automatically syncs the experiment definition to the Experiment Assignment Service (EAS). Clients can then reference this experiment in code (website, mobile, or other services).</p><p>In order to move from a manual process using R/Python scripts to a fully automated system, we first needed to improve the performance of the existing process.</p><h3 id="Rewrite-using-Scala-Spark"><a href="#Rewrite-using-Scala-Spark" class="headerlink" title="Rewrite using Scala/Spark"></a>Rewrite using Scala/Spark</h3><p>The biggest pain point of our previous setup was the time it took for the R/Python scripts to run. These scripts often took hours on a laptop because 1) the scale of our data and 2) the thousands of iterations of repeated A/A tests. However, the nature of this computation lends itself to parallelization. We leveraged our existing data infrastructure and rewrote the scripts using the distributed computing framework, Spark.</p><p>Our current data infrastructure is built on top of Google Cloud Platform. We use a combination of Google Cloud Storage, Google Cloud Dataproc (Spark) and Google BigQuery (SQL) to power our offline jobs. For more details, check out this blog post on our journey moving to GCP.</p><p>The Seedfinder Spark job is triggered when a new seedfinder experiment is synced with EAS. This new experiment will be in a “pending” state until the Seedfinder Spark job successfully finds a randomization salt and updates EAS.</p><p><img src="/images/seedfinder_2.jpg" alt=""></p><p>The Seedfinder job now takes only minutes — a 10X improvement in runtime and saves the operational overhead for our data scientists by automating the end to end process.</p><h3 id="Customization"><a href="#Customization" class="headerlink" title="Customization"></a>Customization</h3><p>As Thumbtack continues to grow, so does our need to experiment on a specific subset of our users. To address this need, we added a feature that lets developers specify the subset of users for an experiment via a reference table.</p><p>A reference table contains the set of users who should participate in the experiment. This table is automatically exposed as a BigQuery table when developers commit SQL logic to a git repo. Developers can configure their experiments to use reference tables in experiment configuration, and the Seedfinder Spark job reads data from reference tables as necessary.</p><h3 id="Putting-it-all-together"><a href="#Putting-it-all-together" class="headerlink" title="Putting it all together"></a>Putting it all together</h3><p>Here’s how the Seedfinder architecture looks like today:</p><p><img src="/images/seedfinder_3.jpg" alt=""></p><h2 id="Takeaways"><a href="#Takeaways" class="headerlink" title="Takeaways"></a>Takeaways</h2><p>There are a couple of things we learned along the way:</p><ul><li>Prioritizing projects at the “right” time. We always knew the manual process to find a seed was not sustainable. However, at the time, there were more pressing projects to tackle, given the low volume of experiments that needed Seedfinder and our limited engineering resources (we are actively #hiring). We chose to solve this problem when the demand for seedfinder experiments kept rising.</li><li>Running online A/B experiments is tricky. This blog post only touches the tip of the iceberg when it comes to the challenges we encounter running experiments in an online marketplace. The interactions between customers and professionals in a two-sided marketplace experiment makes inference using classic techniques challenging. If you are a seasoned data scientist, we have interesting data problems to solve here at Thumbtack!</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;(This blog post was originally published at &lt;a href=&quot;https://www.thumbtack.com/engineering/seedfinder-infrastructure-improve-sample-balan
      
    
    </summary>
    
    
      <category term="spark" scheme="https://www.commitlogs.com/tags/spark/"/>
    
      <category term="google cloud platform" scheme="https://www.commitlogs.com/tags/google-cloud-platform/"/>
    
      <category term="experiments" scheme="https://www.commitlogs.com/tags/experiments/"/>
    
      <category term="a/b testing" scheme="https://www.commitlogs.com/tags/a-b-testing/"/>
    
      <category term="airflow" scheme="https://www.commitlogs.com/tags/airflow/"/>
    
  </entry>
  
  <entry>
    <title>Scala Error Handling With Option, Try or Either</title>
    <link href="https://www.commitlogs.com/2017/06/26/scala-error-handling-with-option-try-either/"/>
    <id>https://www.commitlogs.com/2017/06/26/scala-error-handling-with-option-try-either/</id>
    <published>2017-06-26T14:35:05.000Z</published>
    <updated>2017-12-16T06:39:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>Error handling is one of those things that you probably don’t need to care too much when started with a programming language, but it will become super important once you want to do some serious stuff with it.</p><p>In a traditional imperative language, errors are mostly handled by a <code>try</code> and <code>catch</code> clause. For example, if we are reading something from DynamoDB, we can handle it using the following pattern</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  readDDB()</span><br><span class="line">&#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">Exception</span>(<span class="string">s"Exception caught: <span class="subst">$e</span>."</span>)</span><br><span class="line">&#125;</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"><span class="type">Scala</span> prefers more functional ways to handle errors and it provides a couple of options. <span class="type">Most</span> commonly, `<span class="type">Option</span>`, `<span class="type">Try</span>` or `<span class="type">Either</span>`.</span><br><span class="line"></span><br><span class="line">## <span class="type">Option</span></span><br><span class="line"></span><br><span class="line">`<span class="type">Option</span>` is a powerful data <span class="class"><span class="keyword">type</span> <span class="title">in</span> <span class="title">Scala</span>. <span class="title">It</span> <span class="title">is</span> <span class="title">mostly</span> <span class="title">used</span> <span class="title">to</span> <span class="title">handle</span> <span class="title">nullable</span> <span class="title">values</span>, <span class="title">but</span> <span class="title">it</span> <span class="title">can</span> <span class="title">also</span> <span class="title">be</span> <span class="title">used</span> <span class="title">to</span> <span class="title">passing</span> <span class="title">around</span> <span class="title">exceptions</span> <span class="title">when</span> <span class="title">combined</span> <span class="keyword">with</span> `<span class="title">try</span>` <span class="title">and</span> `<span class="title">catch</span>`. <span class="title">Admittedly</span>, <span class="title">this</span> <span class="title">is</span> <span class="title">not</span> <span class="title">a</span> <span class="title">typical</span> <span class="title">use</span> <span class="title">case</span>, <span class="title">but</span> <span class="title">it</span> <span class="title">often</span> <span class="title">simplifies</span> <span class="title">a</span> <span class="title">great</span> <span class="title">deal</span> <span class="title">of</span> <span class="title">downstream</span> <span class="title">logic</span> <span class="title">when</span> <span class="title">there</span> <span class="title">is</span> <span class="title">only</span> <span class="title">one</span> <span class="title">possible</span> <span class="title">type</span> <span class="title">of</span> <span class="title">exception</span>.</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">Using</span> `<span class="title">Option</span>`, <span class="title">the</span> <span class="title">DynamoDB</span> <span class="title">example</span> <span class="title">could</span> <span class="title">be</span> <span class="title">rewritten</span> <span class="title">as</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">```<span class="title">scala</span></span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">ddbContentOption</span></span>: <span class="type">Option</span>[<span class="type">DdbContent</span>] =</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="type">Some</span>(readDDB())</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</span><br><span class="line">      log.warn(<span class="string">s"Exception caught: <span class="subst">$e</span>."</span>)</span><br><span class="line">      <span class="type">None</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>In this way, the response is of type <code>Option</code> and can be pass along to downstream logics and eventually be handled when it is used.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ddbContentOption.fold &#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> exception(<span class="string">"readDDB throws exception"</span>)</span><br><span class="line">&#125; &#123; <span class="keyword">case</span> c =&gt;</span><br><span class="line">  useDdbContent(c)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Try"><a href="#Try" class="headerlink" title="Try"></a>Try</h2><p>Use <code>Option</code> to pass along exceptions is easy, but also is very limited in terms of the types of exceptions being handled. A more powerful mechanism was introduced in <code>Scala 2.10</code>, i.e., the <code>Try</code> keyword.</p><p><code>Try</code> can be used to wrap around methods, which results in an instance  <code>Try[A]</code> that 1) if the computation is successful, it’s an instance of <code>Success[A]</code>, simply wrapping the value of type <code>A</code>; and 2) if the computation errors out, it’s an instance of <code>Failure[A]</code>, wrapping a <code>Throwable</code>.</p><p>Going back to our toy example, we can rewrite it as </p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.util.<span class="type">Try</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> ddbContent: <span class="type">Try</span>[<span class="type">DdbContent</span>] = <span class="type">Try</span>(readDDB())</span><br></pre></td></tr></table></figure><p>Working with <code>Try</code> values is very similar to <code>Option</code> - you can use all the typical functional sugar with it, such as <code>getOrElse</code>, <code>map</code>/<code>flatMap</code> and for comprehensions.</p><p>Specifically to <code>Try</code>, you can use <code>isSuccess</code> to check if the computation is successful; or use pattern matching to handle success and failure accordingly.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.util.&#123;<span class="type">Success</span>, <span class="type">Failure</span>&#125;</span><br><span class="line"></span><br><span class="line">ddbContent <span class="keyword">match</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Success</span>(lines) =&gt; lines.forEach(println)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Failure</span>(e) =&gt; log.warn(<span class="string">s"Exception caught: <span class="subst">$e</span>."</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Moreover, you don’t have to use <code>getOrElse</code> to set default values for <code>Try</code>. Instead, you could take advantage of the <code>recover</code> or <code>recoverWith</code> methods, which returns a <code>Success</code> by applying a partial function on the given <code>Failure</code> instance.</p><h2 id="Either"><a href="#Either" class="headerlink" title="Either"></a>Either</h2><p>Alternatively, people are also using <code>Either</code> for this purpose. But, similar to <code>Option</code>, <code>Either</code> has its usage outside of error handling.</p><p><code>Either</code> takes two type parameters <code>A</code> and <code>B</code>. An instance of <code>Either[A, B]</code> is either an instance of <code>A</code> or an instance of <code>B</code>, which is defined by two sub types <code>Left</code> and <code>Right</code>. For example, an <code>Either</code> is a <code>Left</code> if it is an instance of <code>A</code>.</p><p>In error handling, the convention is to use the <code>Left</code> to represent the error case and <code>Right</code> for the success value. Therefore, our DynamoDB example can be wrapped using <code>Either</code> in this way</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> ddbContent: <span class="type">Either</span>[<span class="type">String</span>, <span class="type">DdbContent</span>] =</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="type">Right</span>(readDDB())</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt; <span class="type">Left</span>(e.getMessage) </span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>In downstream, we can use pattern matching to handle success or failure.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ddbContent <span class="keyword">match</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Left</span>(msg) =&gt; log.warn(<span class="string">s"Exception caught: <span class="subst">$msg</span>."</span>)</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Right</span>(lines) =&gt; lines.forEach(println) </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Unlike <code>Option</code> or <code>Try</code>, <code>Either</code> is unbiased, which means you need to choose the assumption that it is a <code>Left</code> or <code>Right</code> by calling <code>.left</code> or <code>.right</code>. Then you will get a <code>LeftProjection</code> or <code>RightProjection</code> as a left or right biased wrapper for the <code>Either</code>.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Scala provides a couple of nice APIs to work with error handling, such as <code>Option</code>, <code>Try</code> and <code>Either</code>. It prefers these functional style handling as opposed to the more traditional <code>try</code> and <code>catch</code> with side effects. With a few caveats, you can work with these APIs using standard funcitonal sugars.</p><ol><li>As always, I would really appreciate your thoughts/comments. Feel free to leave them following this post or tweet me <a href="http://twitter.com/home?status=@_LeiG" target="_blank" rel="noopener">@_LeiG</a>.</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Error handling is one of those things that you probably don’t need to care too much when started with a programming language, but it will
      
    
    </summary>
    
    
      <category term="scala" scheme="https://www.commitlogs.com/tags/scala/"/>
    
      <category term="error handling" scheme="https://www.commitlogs.com/tags/error-handling/"/>
    
      <category term="option" scheme="https://www.commitlogs.com/tags/option/"/>
    
      <category term="try" scheme="https://www.commitlogs.com/tags/try/"/>
    
      <category term="either" scheme="https://www.commitlogs.com/tags/either/"/>
    
  </entry>
  
  <entry>
    <title>Find side-project ideas using our old pal Google</title>
    <link href="https://www.commitlogs.com/2017/03/25/find_side-project-ideas-using-our-old-pal-google/"/>
    <id>https://www.commitlogs.com/2017/03/25/find_side-project-ideas-using-our-old-pal-google/</id>
    <published>2017-03-26T03:39:36.000Z</published>
    <updated>2017-03-26T17:12:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>Programmers love side-projects. It’s a great way to stay on top of trending technologies and, sometimes, make some extra dollars. The success of a side-project, however, often has nothing to do with the specific shinny technology you are using. It is about actually FINISHING it. To me, that means starting a project with the end in mind. You have to have some purpose in order to squeeze out the nights and weekends to build it. To that extent, what would be better motivations than some extra income?</p><p>In this post, I will try to lay out a strategy to identify side-project opportunities that can actually get you some passive income. Note it’s not going to get you rich over night, but hopefully you could earn a steady income flow. You ask how? We will use our old pal Google to shed some insights on us.</p><h2 id="Identify-the-opportunity"><a href="#Identify-the-opportunity" class="headerlink" title="Identify the opportunity"></a>Identify the opportunity</h2><p>One of the best way to find massive demand is through Google keywords. Billions of search queries are processed by Google per day, which collectively reflect at least millions of demands.</p><p>If we can leverage that information to our advantage, we can identify a market small enough that no giant companies are present, but large enough for us to earn a significant amount of income. You might be curious how to get this data. Well, guess what, our friend Google is providing that information to us for free through “Related searches”!</p><p><strong>Quiz</strong>: what can you find as a good side-project idea if you search “instagram download” and look at its “Related queries”?</p><p>The query “instagram download photos” immediately stands out. The official website/app doesn’t provide this functionality for obvious reasons, but apparently there is huge demand here (it’s a no-brainer since it is a simple query involving “Instagram” and it ranks high)!</p><h2 id="Research-competitors"><a href="#Research-competitors" class="headerlink" title="Research competitors"></a>Research competitors</h2><p>Now we have a general idea of the demand, we need to do a little bit of research on existing competitors before spending time coding. After all, we as programmers earn a good amount per hour coding anywhere.</p><p>The research also involves using Google ;)  Basically, you just search the query, e.g. “instagram download photos” in our case, and see what the top results are. After that, I often look them up in <a href="https://www.similarweb.com" target="_blank" rel="noopener">SimilarWeb</a>, who would tell you what’s their monthly traffic and other statistics. It gives you both an idea of how large the market is, aka how much you could potentially make, and how fierce is the competition.</p><p>A level deeper, you should also learn how your competitors are attracting traffic. One way is to use <a href="https://www.ahrefs.com" target="_blank" rel="noopener">ahrefs.com</a> to look at their top referring contents. This is super helpful when you start to market your product.</p><p>With these information in mind, I find it also really helpful to actually experience with the competing products. You need to learn from them and see if you have a good idea in terms of innovation or usability. If you do, now it is the time to start coding.</p><h2 id="Build-ship-fast-and-do-marketing"><a href="#Build-ship-fast-and-do-marketing" class="headerlink" title="Build/ship fast and do marketing"></a>Build/ship fast and do marketing</h2><p>Seize this type of opportunities is all about moving fast. Your side-project is no-longer a laid-back toy project, you now have a purpose in mind so go and ship fast! You want to have something out there and start to market it as early as possible so that your site can start to move up in search rankings. At the end of the day, it’s all about SEO since the initial opportunity is found directly through search engine.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>This is something that myself started to explore. It provides me with a good motivation to ship my side-projects and a great experience to run a start-up like business on the side.</p><p>As always, I would really appreciate your thoughts/comments. Feel free to leave them following this post or tweet me <a href="http://twitter.com/home?status=@_LeiG" target="_blank" rel="noopener">@_LeiG</a>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Programmers love side-projects. It’s a great way to stay on top of trending technologies and, sometimes, make some extra dollars. The suc
      
    
    </summary>
    
    
      <category term="side project" scheme="https://www.commitlogs.com/tags/side-project/"/>
    
      <category term="technology" scheme="https://www.commitlogs.com/tags/technology/"/>
    
  </entry>
  
  <entry>
    <title>Caching predictive models using Guava in Scala</title>
    <link href="https://www.commitlogs.com/2017/03/11/caching-predictive-models-using-guava-in-scala/"/>
    <id>https://www.commitlogs.com/2017/03/11/caching-predictive-models-using-guava-in-scala/</id>
    <published>2017-03-12T05:09:40.000Z</published>
    <updated>2017-03-15T06:21:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>In <a href="https://commitlogs.com/2017/02/18/serve-spark-ml-model-using-play-framework-and-s3/" target="_blank" rel="noopener">a previous post</a>, we talked about caching Spark models in memory for a web service so that the prediction latency is reduced. As with any web applications, caching strategy can get very interesting, but the patterns of caching a machine learning model are relatively straightforward, since the model is likely to be static unless there are updates. In particular, I find Guava provides some handy in-memory cache solutions for our use case.</p><p>In the rest of this post, I am going to walk you through some basic caching patterns using Guava. Note that, this is inspired by, but not limited to caching predictive models. As a reference example, we assume the goal is to serve a machine learning model, which is updated daily, in a web application built by the Play Framework.</p><h2 id="Timed-eviction"><a href="#Timed-eviction" class="headerlink" title="Timed eviction"></a>Timed eviction</h2><p>To start with, a simple caching pattern is to load the model in-memory and evict it after a given time period (daily in our case). In our particular case, we will use <code>CacheLoader</code>, since there is a default function (the machine learning model) to load associated with a key (model identifier); otherwise, you will need to pass a <code>Callable</code> into a <code>get</code> call.</p><p>With dependency injection, you could create a <code>CacheProvider</code> for caching.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> controllers</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.<span class="type">TimeUnit</span></span><br><span class="line"><span class="keyword">import</span> com.google.common.cache.&#123;<span class="type">CacheBuilder</span>, <span class="type">CacheLoader</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">CacheProvider</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">val</span> modelCache = <span class="type">CacheBuilder</span>.newBuilder()</span><br><span class="line">    .maximumSize(<span class="number">2</span>)</span><br><span class="line">    .expireAfterWrite(<span class="number">24</span>, <span class="type">TimeUnit</span>.<span class="type">HOURS</span>)</span><br><span class="line">    .build(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">CacheLoader</span>[<span class="type">String</span>, <span class="type">Model</span>]&#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">load</span></span>(path: <span class="type">String</span>): <span class="type">Model</span> = &#123;</span><br><span class="line">          <span class="type">Model</span>.load(path)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getModel</span></span>: <span class="type">Model</span> = &#123;</span><br><span class="line">    modelCache.get(<span class="string">"path/to/model"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In this way, the cached model is evicted after 24 hours. For the immediate next query after eviction, the service will hang there until the model is loaded again so a higher latency is expected.</p><h2 id="Timed-refresh"><a href="#Timed-refresh" class="headerlink" title="Timed refresh"></a>Timed refresh</h2><p>For timed eviction, if things went wrong during reloading, the service won’t be able to return anything because the old model is already evicted. This is of course is not ideal and may cause serious problems.</p><p>Instead, a better solution maybe timed refresh. The difference is that the old model (if any) is still returned while the key is being refreshed. Therefore, even if an exception is thrown while refreshing, the service is still able to return results from the old model, while the exception is logged and swallowed.</p><p>The change to switch from timed eviction to timed refresh is minimal - you just need to replace <code>expireAfterWrite</code> with <code>refreshAfterWrite</code>.</p><h2 id="Timed-asynchronous-refresh"><a href="#Timed-asynchronous-refresh" class="headerlink" title="Timed asynchronous refresh"></a>Timed asynchronous refresh</h2><p>The defauled refresh loads value synchronously. That means, the service will still hang there waiting for the new model to be loaded. This makes queries to have high latency during refresh and, thus, bad user experience.</p><p>Good news is that there is a way to set up the <code>CacheBuilder</code> such that refresh happens asynchronously. Specifically, you need to overwrite the <code>reload</code> method to be asynchronous.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> controllers</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.&#123;<span class="type">Callable</span>, <span class="type">Executors</span>, <span class="type">TimeUnit</span>&#125;</span><br><span class="line"><span class="keyword">import</span> com.google.common.cache.&#123;<span class="type">CacheBuilder</span>, <span class="type">CacheLoader</span>&#125;</span><br><span class="line"><span class="keyword">import</span> com.google.common.util.concurrent.&#123;<span class="type">ListenableFuture</span>, <span class="type">ListenableFutureTask</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">CacheProvider</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">val</span> executor = <span class="type">Executors</span>.newFixedThreadPool(<span class="number">10</span>)</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">val</span> modelCache = <span class="type">CacheBuilder</span>.newBuilder()</span><br><span class="line">    .maximumSize(<span class="number">2</span>)</span><br><span class="line">    .refreshAfterWrite(<span class="number">24</span>, <span class="type">TimeUnit</span>.<span class="type">HOURS</span>)</span><br><span class="line">    .build(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">CacheLoader</span>[<span class="type">String</span>, <span class="type">Model</span>]() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">load</span></span>(path: <span class="type">String</span>): <span class="type">Model</span> = &#123;</span><br><span class="line">          <span class="type">Model</span>.load(path)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// override reload makes refresh asynchronous</span></span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reload</span></span>(</span><br><span class="line">          path: <span class="type">String</span>,</span><br><span class="line">          prevModel: <span class="type">Model</span></span><br><span class="line">        ): <span class="type">ListenableFuture</span>[<span class="type">Model</span>] = &#123;</span><br><span class="line">          <span class="keyword">val</span> task = <span class="type">ListenableFutureTask</span>.create(</span><br><span class="line">            <span class="keyword">new</span> <span class="type">Callable</span>[<span class="type">Model</span>]() &#123;</span><br><span class="line">              <span class="function"><span class="keyword">def</span> <span class="title">call</span></span>(): <span class="type">Model</span> = &#123;</span><br><span class="line">                <span class="type">Model</span>.load(path)</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          )</span><br><span class="line"></span><br><span class="line">          executor.execute(task)</span><br><span class="line">          task</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getModel</span></span>: <span class="type">Model</span> = &#123;</span><br><span class="line">    modelCache.get(<span class="string">"path/to/model"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Caching is one of the most interesting problems in web applications. Here I only talked about some most basic in-memory caching patterns, but they, especially the timed asynchronous refresh, seem to work well with predictive models, which is relatively static compared to other content.</p><p>As always, I would really appreciate your thoughts/comments. Feel free to leave them following this post or tweet me <a href="http://twitter.com/home?status=@_LeiG" target="_blank" rel="noopener">@_LeiG</a>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;In &lt;a href=&quot;https://commitlogs.com/2017/02/18/serve-spark-ml-model-using-play-framework-and-s3/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;a previou
      
    
    </summary>
    
    
      <category term="cache" scheme="https://www.commitlogs.com/tags/cache/"/>
    
      <category term="scala" scheme="https://www.commitlogs.com/tags/scala/"/>
    
      <category term="guava" scheme="https://www.commitlogs.com/tags/guava/"/>
    
      <category term="asynchronous" scheme="https://www.commitlogs.com/tags/asynchronous/"/>
    
      <category term="play framework" scheme="https://www.commitlogs.com/tags/play-framework/"/>
    
  </entry>
  
  <entry>
    <title>Serve Spark ML Models Using Play Framework and S3</title>
    <link href="https://www.commitlogs.com/2017/02/18/serve-spark-ml-model-using-play-framework-and-s3/"/>
    <id>https://www.commitlogs.com/2017/02/18/serve-spark-ml-model-using-play-framework-and-s3/</id>
    <published>2017-02-19T01:49:34.000Z</published>
    <updated>2017-02-23T05:47:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>We had talked about various ways to serve machine learning results in production (see an ealier post <a href="https://commitlogs.com/2016/11/19/predictive-model-deployment-with-spark/" target="_blank" rel="noopener">Predictive Model Deployment with Spark</a> for example). That article outlines three architectures of model serving systems. In particular, I found using Spark’s internal serialization logic to persist/load models to be both flexible and reliable. As a follow-up, in this post, I am going to show case how to serve a simple Spark MLLib machine learning model, i.e. Naive Bayes classifier as an example, in a web application built with the Play Framework, which is one of the most popular web frameworks in Scala/Java.</p><h2 id="Offline-model-training"><a href="#Offline-model-training" class="headerlink" title="Offline model training"></a>Offline model training</h2><p>Today machine learning models are often trained on a large Spark cluster to take advantage of its powerful distributed computing capability and easy-to-use APIs. Since the offline training part is not the focus of this post, I will just build on top of a toy training pipeline from the official <a href="https://spark.apache.org/docs/2.0.2/mllib-naive-bayes.html" target="_blank" rel="noopener">Spark tutorial</a></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.classification.&#123;<span class="type">NaiveBayes</span>, <span class="type">NaiveBayesModel</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.util.<span class="type">MLUtils</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Load and parse the data file.</span></span><br><span class="line"><span class="keyword">val</span> data = <span class="type">MLUtils</span>.loadLibSVMFile(sc, <span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Split data into training (60%) and test (40%).</span></span><br><span class="line"><span class="keyword">val</span> <span class="type">Array</span>(training, test) = data.randomSplit(<span class="type">Array</span>(<span class="number">0.6</span>, <span class="number">0.4</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> model = <span class="type">NaiveBayes</span>.train(training, lambda = <span class="number">1.0</span>, modelType = <span class="string">"multinomial"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> predictionAndLabel = test.map(p =&gt; (model.predict(p.features), p.label))</span><br><span class="line"><span class="keyword">val</span> accuracy = <span class="number">1.0</span> * predictionAndLabel.filter(x =&gt; x._1 == x._2).count() / test.count()</span><br></pre></td></tr></table></figure><h3 id="S3-storage"><a href="#S3-storage" class="headerlink" title="S3 storage"></a>S3 storage</h3><p>There are a few model storage options and I decide to use S3 for its simplicity and avaliability. Moreover, Spark provides nice support to save serialized model directly to S3. All you need to do is to configure your <code>SparkContext</code> with the right S3 credentials and then add the following lines to the previous code snippet.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sc.hadoopConfiguration.set(<span class="string">"fs.s3a.access.key"</span>, <span class="type">YourAWSAccessKeyId</span>)</span><br><span class="line">sc.hadoopConfiguration.set(<span class="string">"fs.s3a.secret.key"</span>, <span class="type">YourAWSSecretKey</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// replace it with your bucket path</span></span><br><span class="line">model.save(sc, <span class="string">"s3a://persisted-models/naivebayesexample"</span>)</span><br></pre></td></tr></table></figure><p>If you go to your AWS console, you could find <code>.parquet</code> files stored under your S3 bucket <code>persisted-models/naivebayesexample</code>, which represent the model internal serialization logic of Spark.</p><p>Note that I am using the <code>s3a</code> URI schema to interact with S3. There are in total three variants as described in <a href="https://wiki.apache.org/hadoop/AmazonS3" target="_blank" rel="noopener">https://wiki.apache.org/hadoop/AmazonS3</a></p><blockquote><p>S3 Native FileSystem (URI scheme: s3n) A native filesystem for reading and writing regular files on S3. The advantage of this filesystem is that you can access files on S3 that were written with other tools. Conversely, other tools can access files written using Hadoop. The disadvantage is the 5GB limit on file size imposed by S3.</p><p>S3A (URI scheme: s3a) A successor to the S3 Native, s3n fs, the S3a: system uses Amazon’s libraries to interact with S3. This allows S3a to support larger files (no more 5GB limit), higher performance operations and more. The filesystem is intended to be a replacement for/successor to S3 Native: all objects accessible from s3n:// URLs should also be accessible from s3a simply by replacing the URL schema.</p><p>S3 Block FileSystem (URI scheme: s3) A block-based filesystem backed by S3. Files are stored as blocks, just like they are in HDFS. This permits efficient implementation of renames. This filesystem requires you to dedicate a bucket for the filesystem - you should not use an existing bucket containing files, or write other files to the same bucket. The files stored by this filesystem can be larger than 5GB, but they are not interoperable with other S3 tools.</p></blockquote><p>I choose to use S3A is because 1) it is an object-based overlay on top of S3, unlike S3 Block FileSystem, and 2) it has better performance and suports object up to 5TB compared to S3 Native FileSystem with 5GB object size limit.</p><h2 id="Online-model-serving"><a href="#Online-model-serving" class="headerlink" title="Online model serving"></a>Online model serving</h2><p>Now let’s come to the online serving part. To save some time, I am assuming you already have a Play application up and running (I may write a follow-up post to explain how to set up a minimal web application using the Play Framework, which should be fairly straightforward). For now, let’s also assume the project name of the Play application is <code>yoda</code> and its skeleton looks like the following.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">yoda/</span><br><span class="line">  app/</span><br><span class="line">    controllers/</span><br><span class="line">      Application.scala</span><br><span class="line">    views/</span><br><span class="line">      index.scala.html</span><br><span class="line">      main.scala.html</span><br><span class="line">  conf/</span><br><span class="line">    application.conf</span><br><span class="line">    routes</span><br><span class="line">  public/</span><br><span class="line">  build.sbt</span><br></pre></td></tr></table></figure><h3 id="Add-dependencies"><a href="#Add-dependencies" class="headerlink" title="Add dependencies"></a>Add dependencies</h3><p>The trained model is saved on S3 already at this moment, what we want is to load up the model in memory for <code>yoda</code>. To achieve this, additional dependencies need to be added to the web application. Specifically, we need to add </p><ul><li><code>guava</code>: dependency injection and cache</li><li><code>hadoop</code>: read files from AWS S3</li><li><code>spark</code>: deserialize parquet files to Spark ML model and make predictions</li></ul><p>You can add these dependencies in the <code>build.sbt</code> file by adding the following lines.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">libraryDependencies ++= <span class="type">Seq</span>(</span><br><span class="line">  jdbc,</span><br><span class="line">  anorm,</span><br><span class="line">  cache,</span><br><span class="line">  <span class="string">"com.google.guava"</span>  %% <span class="string">"guava"</span>                   % <span class="string">"19.0"</span>,</span><br><span class="line">  <span class="string">"org.apache.spark"</span>  %% <span class="string">"spark-core"</span>              % <span class="string">"2.0.0"</span>,</span><br><span class="line">  <span class="string">"org.apache.spark"</span>  %% <span class="string">"spark-hive"</span>            % <span class="string">"2.0.0"</span>,</span><br><span class="line">  <span class="string">"org.apache.spark"</span>  %% <span class="string">"spark-sql"</span>               % <span class="string">"2.0.0"</span>,</span><br><span class="line">  <span class="string">"org.apache.spark"</span>  %% <span class="string">"spark-mllib"</span>             % <span class="string">"2.0.0"</span>,</span><br><span class="line">  <span class="string">"org.apache.hadoop"</span> %% <span class="string">"hadoop-aws"</span>              % <span class="string">"2.7.3"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="Load-model-from-S3"><a href="#Load-model-from-S3" class="headerlink" title="Load model from S3"></a>Load model from S3</h3><p>With these dependencies, we can now load trained model from S3 to memory. Note that we can use some cache mechanism to keep the model in memory for prediction and refresh it if the model is updated. For similicity, we are going to keep the model in memory and refresh every 24 hours in this toy example. More complex caching logic should be use case specific.</p><p>The logic can be added to <code>CacheProvider.scala</code> under <code>controllers/</code>, i.e.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">controllers/</span><br><span class="line">  Application.scala</span><br><span class="line">  CacheProvider.scala</span><br></pre></td></tr></table></figure><p>such that</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> controllers</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.<span class="type">TimeUnit</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.google.common.cache.&#123;<span class="type">CacheBuilder</span>, <span class="type">CacheLoader</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.classification.<span class="type">NaiveBayesModel</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">CacheProvider</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local"</span>).setAppName(<span class="string">"yoda"</span>)</span><br><span class="line">      .set(<span class="string">"spark.driver.host"</span>, <span class="string">"localhost"</span>)</span><br><span class="line">      .set(<span class="string">"spark.driver.allowMultipleContexts"</span>, <span class="string">"true"</span>)</span><br><span class="line">  <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"></span><br><span class="line">  sc.hadoopConfiguration.set(<span class="string">"fs.s3n.awsAccessKeyId"</span>, <span class="type">YourAWSAccessKeyId</span>)</span><br><span class="line">  sc.hadoopConfiguration.set(<span class="string">"fs.s3n.awsSecretAccessKey"</span>, <span class="type">YourAWSSecretKey</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> naiveBayesModelCache = <span class="type">CacheBuilder</span>.newBuilder()</span><br><span class="line">    .maximumSize(<span class="number">2</span>)</span><br><span class="line">    .refreshAfterWrite(<span class="number">24</span>, <span class="type">TimeUnit</span>.<span class="type">HOURS</span>)</span><br><span class="line">    .build(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">CacheLoader</span>[<span class="type">String</span>, <span class="type">NaiveBayesModel</span>]&#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">load</span></span>(path: <span class="type">String</span>): <span class="type">NaiveBayesModel</span> = &#123;</span><br><span class="line">          <span class="type">NaiveBayesModel</span>.load(sc, path)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getNaiveBayesModel</span></span>: <span class="type">NaiveBayesModel</span> = &#123;</span><br><span class="line">    naiveBayesModelCache.get(<span class="string">"s3n://persisted-models/naivebayesexample"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Essentially, the web application <code>yoda</code> runs a Spark in local mode and use its built-in functionality to load the saved model from S3. This approach is pretty generic in the sense that all types of models <code>.save</code> to S3 can be loaded in memory by a web application with minimal code changes.</p><h3 id="Make-online-prediction"><a href="#Make-online-prediction" class="headerlink" title="Make online prediction"></a>Make online prediction</h3><p>Once the Spark ML model is loaded in memory, making prediction based on incoming request is straightforward. Most Spark ML models have a built-in <code>.predict</code> method that takes in an array of features and returns a prediction score.</p><p>You can add the following lines to your <code>Application.scala</code> to make predictions on randomly generated features.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> controllers</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> play.api._</span><br><span class="line"><span class="keyword">import</span> play.api.mvc._</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.concurrent.<span class="type">Future</span></span><br><span class="line"><span class="keyword">import</span> scala.concurrent.<span class="type">ExecutionContext</span>.<span class="type">Implicits</span>._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Application</span> <span class="keyword">extends</span> <span class="title">Controller</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">index</span> </span>= <span class="type">Action</span>.async &#123;</span><br><span class="line">      <span class="keyword">val</span> f: <span class="type">Future</span>[<span class="type">Double</span>] = <span class="type">Future</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// random generate inputs</span></span><br><span class="line">        <span class="keyword">val</span> testInput = <span class="type">Vectors</span>.dense(<span class="type">Array</span>.fill(<span class="number">692</span>)(<span class="type">Random</span>.nextInt).map(_.toDouble))</span><br><span class="line"></span><br><span class="line">        <span class="type">CacheProvider</span>.getNaiveBayesModel.predict(testInput)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      f.map &#123; i =&gt; <span class="type">Ok</span>(views.html.index(i.toString)) &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Building machine learning models are fun and challenging, but, at the end of the day, we want to serve them to our users. This often means expose some endpoints in a web service. The described method in this post aims to provide a generic way to serve all kinds of machine learning models to improve the experience of our users. </p><p>As always, I would really appreciate your thoughts/comments. Feel free to leave them following this post or tweet me @_LeiG.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;We had talked about various ways to serve machine learning results in production (see an ealier post &lt;a href=&quot;https://commitlogs.com/2016
      
    
    </summary>
    
    
      <category term="scala" scheme="https://www.commitlogs.com/tags/scala/"/>
    
      <category term="play framework" scheme="https://www.commitlogs.com/tags/play-framework/"/>
    
      <category term="s3" scheme="https://www.commitlogs.com/tags/s3/"/>
    
      <category term="machine learning" scheme="https://www.commitlogs.com/tags/machine-learning/"/>
    
      <category term="spark" scheme="https://www.commitlogs.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>How To Set up a Gulp Script for Faster Front-end Development</title>
    <link href="https://www.commitlogs.com/2017/01/28/how-to-set-up-gulp-for-front-end-development/"/>
    <id>https://www.commitlogs.com/2017/01/28/how-to-set-up-gulp-for-front-end-development/</id>
    <published>2017-01-28T16:34:45.000Z</published>
    <updated>2017-01-29T01:38:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>Front-end development is an interesting beast of its own. It mostly deals with user experience, which requires constant tuning of page layout and experience flow. </p><p>Do you find yourself refresh that page for the 18 times? Do you find yourself run the script every time before deployment to uglify the page? There is a ton of room for automation here!</p><p>Most famously, the Front-end world seems to be using Gulp or Grunt for this kind of task (this statement may be false very soon with the speed of tool iteration in the JS community). Not to spark any debates here, but I am pretty happy with Gulp, mainly because of its pipelining operators feels very functional.</p><p>This post outlines a simple setup that I borrowed from various places and it should be enough to get you started with automating many of the repetitive tasks. </p><p>Setting up Gulp is relatively straightforward, you first need to install Gulp globally to use it as a command line tool. With <code>yarn</code>, this is as easy as</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn global add gulp</span><br></pre></td></tr></table></figure><p>For Gulp to run within a project, at the root of the project folder, you need to create a <code>gulpfile.js</code> file with</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> gulp = required(<span class="string">'gulp'</span>);</span><br></pre></td></tr></table></figure><p>A common use case of Gulp is to automatically uglify/minify the <code>.css</code>, <code>.js</code> and <code>.html</code> files. This is a required step before any front-end deployment to reduce the size of files being shipped to clients. A few packages are used to achieve this goal, which can be introduced as development dependencies for your project by</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yarn dev add gulp-clean-css, gulp-uglify, gulp-contact, \</span><br><span class="line">             gulp-sourcemaps, gulp-minify-html</span><br></pre></td></tr></table></figure><p>Another use case is to generate various size of an images for responsive design. It usually means modify the dimension and quality of an image so that it could be displayed reasonable and fast on either desktop or phones. That’s a part of the UI usually requires constant iterations and refinement. A handy package can be used to save time by auto modify images as you iterate.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn dev add gulp-responsive</span><br></pre></td></tr></table></figure><p>Lastly, and this is a killing feature in my eyes, Gulp saves you from refreshing the page hundreds of times – an inevitable action during front-end development. The way it works is Gulp runs a test web server that constantly watching the directories and refresh the page once it detects a change. For this to work, another package needs to be installed.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn dev add gulp-webserver</span><br></pre></td></tr></table></figure><p>Assuming you put all the raw files inside a <code>source</code> folder and want to have your optimized files inside a <code>build</code> folder, you could add the following code into the <code>gulpfile.js</code> to achieve all the automation listed above.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> gulp = <span class="built_in">require</span>(<span class="string">'gulp'</span>);</span><br><span class="line"><span class="keyword">var</span> minifycss = <span class="built_in">require</span>(<span class="string">'gulp-clean-css'</span>);</span><br><span class="line"><span class="keyword">var</span> webserver = <span class="built_in">require</span>(<span class="string">'gulp-webserver'</span>);</span><br><span class="line"><span class="keyword">var</span> uglify = <span class="built_in">require</span>(<span class="string">'gulp-uglify'</span>);</span><br><span class="line"><span class="keyword">var</span> concatify = <span class="built_in">require</span>(<span class="string">'gulp-concat'</span>);</span><br><span class="line"><span class="keyword">var</span> sourcemaps = <span class="built_in">require</span>(<span class="string">'gulp-sourcemaps'</span>);</span><br><span class="line"><span class="keyword">var</span> minifyhtml = <span class="built_in">require</span>(<span class="string">'gulp-minify-html'</span>);</span><br><span class="line"><span class="keyword">var</span> responsive = <span class="built_in">require</span>(<span class="string">'gulp-responsive'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Paths to various files</span></span><br><span class="line"><span class="keyword">var</span> paths = &#123;</span><br><span class="line">    scripts: [<span class="string">'source/js/*.js'</span>],</span><br><span class="line">    styles: [<span class="string">'source/css/**/*.css'</span>],</span><br><span class="line">    images: [<span class="string">'source/image/**/*'</span>],</span><br><span class="line">    content: [<span class="string">'source/index.html'</span>]</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Compress css files and outputs them to build/css/*.css</span></span><br><span class="line">gulp.task(<span class="string">'styles'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.src(paths.styles)</span><br><span class="line">        .pipe(minifycss(&#123;<span class="attr">compatibility</span>: <span class="string">'ie8'</span>&#125;))</span><br><span class="line">        .pipe(gulp.dest(<span class="string">'./build/css/'</span>));</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Concats &amp; minifies js files and outputs them to build/js/app.js</span></span><br><span class="line">gulp.task(<span class="string">'scripts'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.src(paths.scripts)</span><br><span class="line">        .pipe(sourcemaps.init())</span><br><span class="line">            .pipe(uglify())</span><br><span class="line">            .pipe(concatify(<span class="string">'app.js'</span>))</span><br><span class="line">        .pipe(sourcemaps.write())</span><br><span class="line">        .pipe(gulp.dest(<span class="string">'./build/js/'</span>));</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Minifies our HTML files and outputs them to build/*.html</span></span><br><span class="line">gulp.task(<span class="string">'content'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.src(paths.content)</span><br><span class="line">        .pipe(minifyhtml(&#123;</span><br><span class="line">            empty: <span class="literal">true</span>,</span><br><span class="line">            quotes: <span class="literal">true</span></span><br><span class="line">        &#125;))</span><br><span class="line">        .pipe(gulp.dest(<span class="string">'./build'</span>));</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Optimizes our image files and outputs them to build/image/*</span></span><br><span class="line">gulp.task(<span class="string">'images'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> gulp.src(paths.images)</span><br><span class="line">        .pipe(responsive(&#123;</span><br><span class="line">            <span class="string">'hero.jpg'</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    width: <span class="number">960</span>,</span><br><span class="line">                    height: <span class="number">450</span>,</span><br><span class="line">                    rename: <span class="string">'hero-large.jpg'</span></span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    width: <span class="number">515</span>,</span><br><span class="line">                    height: <span class="number">465</span>,</span><br><span class="line">                    rename: <span class="string">'hero-small.jpg'</span></span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            <span class="string">'project-*.jpg'</span>: &#123;</span><br><span class="line">                width: <span class="number">250</span>,</span><br><span class="line">                height: <span class="number">250</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,&#123;</span><br><span class="line">            errorOnUnusedImage: <span class="literal">false</span></span><br><span class="line">        &#125;))</span><br><span class="line">        .pipe(gulp.dest(<span class="string">'./build/image/'</span>));</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Watches for changes to our files and executes required scripts</span></span><br><span class="line">gulp.task(<span class="string">'watch'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    gulp.watch(paths.scripts, [<span class="string">'scripts'</span>]);</span><br><span class="line">    gulp.watch(paths.styles, [<span class="string">'styles'</span>]);</span><br><span class="line">    gulp.watch(paths.content, [<span class="string">'content'</span>]);</span><br><span class="line">    gulp.watch(paths.images, [<span class="string">'images'</span>]);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Launches a test webserver</span></span><br><span class="line">gulp.task(<span class="string">'webserver'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    gulp.src(<span class="string">'./build'</span>)</span><br><span class="line">        .pipe(webserver(&#123;</span><br><span class="line">            livereload: <span class="literal">true</span>,</span><br><span class="line">            fallback: <span class="string">"index.html"</span>,</span><br><span class="line">            port: <span class="number">8080</span></span><br><span class="line">        &#125;));</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">gulp.task(<span class="string">'default'</span>, [<span class="string">'styles'</span>, <span class="string">'scripts'</span>, <span class="string">'content'</span>, <span class="string">'images'</span>, <span class="string">'watch'</span>, <span class="string">'webserver'</span>]);</span><br></pre></td></tr></table></figure><p>And, with that, you could just hit the following command in the project’s root directory and watch magic to happen.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gulp</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Front-end development is an interesting beast of its own. It mostly deals with user experience, which requires constant tuning of page la
      
    
    </summary>
    
    
      <category term="javascript" scheme="https://www.commitlogs.com/tags/javascript/"/>
    
      <category term="gulp" scheme="https://www.commitlogs.com/tags/gulp/"/>
    
      <category term="front-end" scheme="https://www.commitlogs.com/tags/front-end/"/>
    
  </entry>
  
  <entry>
    <title>Comparison Between AWS DynamoDB and S3 for Model Metrics Storage</title>
    <link href="https://www.commitlogs.com/2017/01/21/comparison-between-aws-dynamodb-and-s3-for-model-metrics-storage/"/>
    <id>https://www.commitlogs.com/2017/01/21/comparison-between-aws-dynamodb-and-s3-for-model-metrics-storage/</id>
    <published>2017-01-21T19:09:06.000Z</published>
    <updated>2017-01-21T22:02:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>As part of the task to automate our production modeling pipeline, I was exploring options for storing offline training metrics on AWS. The goal is two-fold: 1) to keep tracking of training evaluation metrics and 2) for our internal web app to consume and display this data.</p><p>AWS provides various storage options such as file storage system S3 and NoSQL database DynamoDB. This post summarizes the differences between these two services and how/why we choose one over the other. Bear in mind that the comparison between two services here is based on our specific use case.</p><h2 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h2><p>Fundamentally, S3 and DynamoDB are different storage systems - one is a file system and the other is a database.</p><h3 id="S3"><a href="#S3" class="headerlink" title="S3"></a>S3</h3><p>S3 is basically a file storage system that treats everything as an <code>object</code>. But, before that, there is the concept of a <code>bucket</code>. This is essentially a top level folder that is used to group the data from your various applications. For example, you could you one <code>bucket</code> that stores your log files and another <code>bucket</code> to backup your database. You could configure different permission and other settings for each <code>bucket</code>.</p><p>Besides <code>bucket</code>, S3 actually doesn’t have a folder structure per-se. That means, S3 treats everything inside of a <code>bucket</code> as a group of a flattened group of <code>object</code>.The <code>listKey</code> API would return the keys, or, file names, in layman’s term, of all <code>object</code> within a bucket. However, you can somewhat force a folder structure by naming <code>object</code> with a prefix such as <code>example/</code> so that the <code>object</code> is stored as <code>example/foo</code> in the bucket. To list all keys within that “folder”, you can pass a prefix <code>example/</code> to the API.</p><p>A <code>object</code> in S3 can be as large as 5TB so it’s very suitable for storing large objects. The latency is higher than DynamoDB but it supports concurrency out of the box, which means you can do a lot more things without worrying too much.</p><p>S3 has basic HTTP compatibility so that any applications can be pointed straight to a <code>bucket</code>. It also supports versioning so that you can keep multiple variants of an <code>object</code> in the same <code>bucket</code>, although you need to turn it on deliberately as it’s off by default.</p><h3 id="DynamoDB"><a href="#DynamoDB" class="headerlink" title="DynamoDB"></a>DynamoDB</h3><p>DynamoDB is a No-SQL database that can be used as a key-value store. Its selling point is the low latency/high availability and the scalability. It is really good for storing a lot of small items, since one of its limitation is the 400kb item size limit (including the binary length of both attribute name and attribute value), which was sort of a deal-breaker for our use case, since some of the model metrics could be pretty large given the size of the dataset.</p><p>Every value stored in DynamoDB is keyed by a unique primary key that is consisted of a hash key and a range key. AWS suggest to keep the hash key unique as well for ensuring uniform load distribution, but it’s not required. Because of its database nature, DynamoDB has better query performance with reasonable index structures and, thus, scan is generally discourage.</p><p>Each DynamoDB table has three geographically distributed replicas on SSD to ensure high availability, low latency and data durability.</p><h2 id="Pricing"><a href="#Pricing" class="headerlink" title="Pricing"></a>Pricing</h2><p>The pricing models are also drastically different for two services, the cost of which could be huge if one doesn’t make a thoughtful choice based on usage.</p><h3 id="S3-1"><a href="#S3-1" class="headerlink" title="S3"></a>S3</h3><p>S3’s pricing model is straightforward - it essentially charges a unit price per GB usage. Specifically, AWS charges a storage price, a request price and a data transfer price. The price is overall pretty cheap since the primary use cases of S3 are storing huge amount of data. I found this <a href="http://calculator.s3.amazonaws.com/index.html" target="_blank" rel="noopener">simple price calculator</a> to be very helpful.</p><h3 id="DynamoDB-1"><a href="#DynamoDB-1" class="headerlink" title="DynamoDB"></a>DynamoDB</h3><p>DynamoDB has a little more complicated pricing model. It depends on a pre-specified throughput capacity (in units), a storage price, an optional service named DynamoDB Streams and data transfer fee.</p><p>The throughput capacity is used to provision the table. It includes a read and a write capacity, which hides a lot of complexities from developers. After the throughput capacity is specified, a flat, hourly rate will be charged. The storage price is on a S3-like model, where a unit price per GB is charged, including the uploaded data size and a fixed indexing overhead. Again, a <a href="http://calculator.s3.amazonaws.com/index.html#s=DYNAMODB" target="_blank" rel="noopener">price calculator</a> is available to estimate your monthly charge.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In summary, S3 and DynamoDB are both great AWS services with different use cases in mind. S3 is a general storage solution targeting users with needs to store a huge amount of unstructured data. DynamoDB is a No-SQL database set out to solve the scalability challenge for many web applications.</p><p>For us, since the offline metrics storage can be pretty large with potential unstructured data such as figures, S3 seems to be the viable choice of the two. Plus, the summarized offline metrics are consumed by an internal web app with an infrequent fashion - S3 could help us to save a few bucks as well.</p><p>As always, I would really appreciate your thoughts/comments. Feel free to leave them following this post or tweet me <a href="http://twitter.com/home?status=@_LeiG" target="_blank" rel="noopener">@_LeiG</a>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;As part of the task to automate our production modeling pipeline, I was exploring options for storing offline training metrics on AWS. Th
      
    
    </summary>
    
    
      <category term="s3" scheme="https://www.commitlogs.com/tags/s3/"/>
    
      <category term="dynamodb" scheme="https://www.commitlogs.com/tags/dynamodb/"/>
    
      <category term="aws" scheme="https://www.commitlogs.com/tags/aws/"/>
    
  </entry>
  
  <entry>
    <title>Serialize and deserialize JSON with json4s in Scala</title>
    <link href="https://www.commitlogs.com/2017/01/14/serialize-deserialize-json-with-json4s-in-scala/"/>
    <id>https://www.commitlogs.com/2017/01/14/serialize-deserialize-json-with-json4s-in-scala/</id>
    <published>2017-01-14T15:41:27.000Z</published>
    <updated>2017-01-21T22:02:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>JSON is a widely used protocol for communication between services. Recently, I was tasked to write some serialization/deserialization logic in Scala, so I did a bit research and find <code>json4s</code> to be an effective option for my use case. Here are some simple code snippets to get started with this library.</p><h2 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h2><p>JSON AST is used to model the structure of a JSON document, which is the fundamental building block of <code>json4s</code>. </p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">sealed</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">JValue</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">object</span> <span class="title">JNothing</span> <span class="keyword">extends</span> <span class="title">JValue</span> <span class="title">//</span> '<span class="title">zero</span>' <span class="title">for</span> <span class="title">JValue</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">object</span> <span class="title">JNull</span> <span class="keyword">extends</span> <span class="title">JValue</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">JString</span>(<span class="params">s: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">JValue</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">JDouble</span>(<span class="params">num: <span class="type">Double</span></span>) <span class="keyword">extends</span> <span class="title">JValue</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">JDecimal</span>(<span class="params">num: <span class="type">BigDecimal</span></span>) <span class="keyword">extends</span> <span class="title">JValue</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">JInt</span>(<span class="params">num: <span class="type">BigInt</span></span>) <span class="keyword">extends</span> <span class="title">JValue</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">JBool</span>(<span class="params">value: <span class="type">Boolean</span></span>) <span class="keyword">extends</span> <span class="title">JValue</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">JObject</span>(<span class="params">obj: <span class="type">List</span>[<span class="type">JField</span>]</span>) <span class="keyword">extends</span> <span class="title">JValue</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">JArray</span>(<span class="params">arr: <span class="type">List</span>[<span class="type">JValue</span>]</span>) <span class="keyword">extends</span> <span class="title">JValue</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">type</span> <span class="title">JField</span> </span>= (<span class="type">String</span>, <span class="type">JValue</span>)</span><br></pre></td></tr></table></figure><p>Features are implemented based on AST such as functions used to transform the AST itself, or between the AST and other formats.</p><h2 id="Serialization"><a href="#Serialization" class="headerlink" title="Serialization"></a>Serialization</h2><p>We can serialize Scala objects, such as  <code>case class</code> into JSON easily with json4s default formats.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.json4s._</span><br><span class="line"><span class="keyword">import</span> org.json4s.jackson.<span class="type">Serialization</span></span><br><span class="line"><span class="keyword">import</span> org.json4s.jackson.<span class="type">Serialization</span>.write</span><br><span class="line"></span><br><span class="line"><span class="keyword">implicit</span> <span class="keyword">val</span> formats = <span class="type">DefaultFormats</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Employee</span>(<span class="params">id: <span class="type">Int</span>, firstName: <span class="type">String</span>, lastName: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">Address</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  streetAddress: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  city: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  state: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  country: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  zipcode: <span class="type">String</span></span></span></span><br><span class="line"><span class="class"><span class="params"></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">Company</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  id: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  name: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  address: <span class="type">Address</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  employees: <span class="type">List</span>[<span class="type">Employee</span>]</span></span></span><br><span class="line"><span class="class"><span class="params"></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">piedPier</span> </span>= <span class="type">Company</span>(</span><br><span class="line">id = <span class="number">1</span>,</span><br><span class="line">  name = <span class="string">"pied piper"</span>,</span><br><span class="line">  address = <span class="type">Address</span>(</span><br><span class="line">    streetAddress = <span class="string">"5230 Newell Road"</span>,</span><br><span class="line">    city = <span class="string">"Palo Alto"</span>,</span><br><span class="line">    state = <span class="string">"CA"</span>,</span><br><span class="line">    country = <span class="string">"USA"</span>,</span><br><span class="line">    zipcode = <span class="string">"94301"</span></span><br><span class="line">  ),</span><br><span class="line">  employees = <span class="type">List</span>(</span><br><span class="line">    <span class="type">Employee</span>(<span class="number">1</span>, <span class="string">"Richard"</span>, <span class="string">"Hendricks"</span>),</span><br><span class="line">    <span class="type">Employee</span>(<span class="number">2</span>, <span class="string">"Jared"</span>, <span class="string">"Dunn"</span>),</span><br><span class="line">    <span class="type">Employee</span>(<span class="number">3</span>, <span class="string">"Dinesh"</span>, <span class="string">"Chugtal"</span>),</span><br><span class="line">    <span class="type">Employee</span>(<span class="number">4</span>, <span class="string">"Bertram"</span>, <span class="string">"Gilfoyle"</span>),</span><br><span class="line">    <span class="type">Employee</span>(<span class="number">5</span>, <span class="string">"Erlich"</span>, <span class="string">"Bachman"</span>)</span><br><span class="line">  )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// serialize piedPier</span></span><br><span class="line"><span class="keyword">val</span> piedPierJSON = write(piedPier)</span><br></pre></td></tr></table></figure><p>And, walla, you get what you want!</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&#123; <span class="attr">"id"</span>: <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"address"</span>: &#123;</span><br><span class="line">    <span class="attr">"streetAddress"</span>: <span class="string">"5230 Newell Road"</span>,</span><br><span class="line">    <span class="attr">"city"</span>: <span class="string">"Palo Alto"</span>,</span><br><span class="line">    <span class="attr">"state"</span>: <span class="string">"CA"</span>,</span><br><span class="line">    <span class="attr">"country"</span>: <span class="string">"USA"</span>,</span><br><span class="line">    <span class="attr">"zipcode"</span>: <span class="string">"94301"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"employees"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"id"</span>: <span class="number">1</span>,</span><br><span class="line">      <span class="attr">"firstName"</span>: <span class="string">"Richard"</span>,</span><br><span class="line">      <span class="attr">"lastName"</span>: <span class="string">"Hendricks"</span> </span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"id"</span>: <span class="number">2</span>,</span><br><span class="line">      <span class="attr">"firstName"</span>: <span class="string">"Jared"</span>,</span><br><span class="line">      <span class="attr">"lastName"</span>: <span class="string">"Dunn"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"id"</span>: <span class="number">3</span>,</span><br><span class="line">      <span class="attr">"firstName"</span>: <span class="string">"Dinesh"</span>,</span><br><span class="line">      <span class="attr">"lastName"</span>: <span class="string">"Chugtal"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"id"</span>: <span class="number">4</span>,</span><br><span class="line">      <span class="attr">"firstName"</span>: <span class="string">"Bertram"</span>,</span><br><span class="line">      <span class="attr">"lastName"</span>: <span class="string">"Gilfoyle"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"id"</span>: <span class="number">5</span>,</span><br><span class="line">      <span class="attr">"firstName"</span>: <span class="string">"Erlich"</span>,</span><br><span class="line">      <span class="attr">"lastName"</span>: <span class="string">"Bachman"</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>As you can see, the serialization is super easy for simple case classes and it supports the following out-of-box:</p><ul><li>Arbitrarily deep case class graphs</li><li>All primitive types, including BigInt and Symbol</li><li>List, Seq, Array, Set and Map (note, keys of the Map must be strings: Map[String, _])</li><li>scala.Option</li><li>java.util.Date</li><li>Polymorphic Lists (see below)</li><li>Recursive types</li><li>Serialization of fields of a class</li></ul><p>Of course, you might already started asking how about more complicated use cases. Luckily, json4s supports customized serialization logic as well with a little bit of extra work.</p><p>For illustration, let’s assume our <code>Employee</code> case class is not serializable by default, we can plug in a customized serializer to achieve the same results.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EmployeeSerializer</span> <span class="keyword">extends</span> <span class="title">CustomSerializer</span>[<span class="type">Employee</span>] (<span class="params">format =&gt;</span></span></span><br><span class="line"><span class="class"><span class="params">  &#123;</span></span></span><br><span class="line"><span class="class"><span class="params">    case <span class="type">JObject</span>(</span></span></span><br><span class="line"><span class="class"><span class="params">      <span class="type">JField</span>("id", <span class="type">JInt</span>(d</span>)) </span>::</span><br><span class="line">      <span class="type">JField</span>(<span class="string">"firstName"</span>, <span class="type">JString</span>(f)) ::</span><br><span class="line">      <span class="type">JField</span>(<span class="string">"lastName"</span>, <span class="type">JString</span>(l))</span><br><span class="line">    ) =&gt; <span class="keyword">new</span> <span class="type">Employee</span>(d.int, f.string, l.string)</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">case</span> x: <span class="type">Employee</span> =&gt; <span class="type">JObject</span>(</span><br><span class="line">      <span class="type">JField</span>(<span class="string">"id"</span>, <span class="type">JInt</span>(<span class="type">Int</span>(x.id))) :: </span><br><span class="line">      <span class="type">JField</span>(<span class="string">"firstName"</span>, <span class="type">JString</span>(<span class="type">String</span>(x.firstName)))) ::</span><br><span class="line">      <span class="type">JField</span>(<span class="string">"lastName"</span>, <span class="type">JString</span>(<span class="type">String</span>(x.lastName)))</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">implicit</span> <span class="keyword">val</span> formats = <span class="type">Serialization</span>.formats(<span class="type">NoTypeHints</span>) + <span class="keyword">new</span> <span class="type">EmployeeSerializer</span></span><br></pre></td></tr></table></figure><p>The syntax is pretty straightforward to create a customized serializer and you can just plug it in as you would do with the default one.</p><h2 id="Deserialization"><a href="#Deserialization" class="headerlink" title="Deserialization"></a>Deserialization</h2><p>The deserialization is just a one-liner if you happen to serialize the JSON object with the above logic.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.json4s._</span><br><span class="line"><span class="keyword">import</span> org.json4s.jackson.<span class="type">Serialization</span></span><br><span class="line"><span class="keyword">import</span> org.json4s.jackson.<span class="type">Serialization</span>.read</span><br><span class="line"></span><br><span class="line"><span class="keyword">implicit</span> <span class="keyword">val</span> formats = <span class="type">DefaultFormats</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Employee</span>(<span class="params">id: <span class="type">Int</span>, firstName: <span class="type">String</span>, lastName: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">Address</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  streetAddress: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  city: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  state: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  country: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  zipcode: <span class="type">String</span></span></span></span><br><span class="line"><span class="class"><span class="params"></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">Company</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  id: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  name: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  address: <span class="type">Address</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  employees: <span class="type">List</span>[<span class="type">Employee</span>]</span></span></span><br><span class="line"><span class="class"><span class="params"></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">piedPier</span> </span>= read[<span class="type">Company</span>](piedPierJSON)</span><br></pre></td></tr></table></figure><p>In fact, for any JSON string, we just also deserialize it by</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">implicit</span> <span class="keyword">val</span> formats = <span class="type">DefaultFormats</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> piedPierJSON = parse(<span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">&#123; "</span><span class="string">id": 1,</span></span><br><span class="line"><span class="string">  "</span><span class="string">address": &#123;</span></span><br><span class="line"><span class="string">    "</span>streetA<span class="string">ddress": "</span><span class="number">5230</span> <span class="type">Newell</span> <span class="type">Road</span><span class="string">",</span></span><br><span class="line"><span class="string">    "</span><span class="string">city": "</span><span class="type">Palo</span> <span class="type">Alto</span><span class="string">",</span></span><br><span class="line"><span class="string">    "</span><span class="string">state": "</span><span class="type">CA</span><span class="string">",</span></span><br><span class="line"><span class="string">    "</span><span class="string">country": "</span><span class="type">USA</span><span class="string">",</span></span><br><span class="line"><span class="string">    "</span><span class="string">zipcode": "</span><span class="number">94301</span><span class="string">"</span></span><br><span class="line"><span class="string">  &#125;,</span></span><br><span class="line"><span class="string">  "</span><span class="string">employees": [</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      "</span><span class="string">id": 1,</span></span><br><span class="line"><span class="string">      "</span>firstN<span class="string">ame": "</span><span class="type">Richard</span><span class="string">",</span></span><br><span class="line"><span class="string">      "</span>lastN<span class="string">ame": "</span><span class="type">Hendricks</span><span class="string">" </span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      "</span><span class="string">id": 2,</span></span><br><span class="line"><span class="string">      "</span>firstN<span class="string">ame": "</span><span class="type">Jared</span><span class="string">",</span></span><br><span class="line"><span class="string">      "</span>lastN<span class="string">ame": "</span><span class="type">Dunn</span><span class="string">"</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      "</span><span class="string">id": 3,</span></span><br><span class="line"><span class="string">      "</span>firstN<span class="string">ame": "</span><span class="type">Dinesh</span><span class="string">",</span></span><br><span class="line"><span class="string">      "</span>lastN<span class="string">ame": "</span><span class="type">Chugtal</span><span class="string">"</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      "</span><span class="string">id": 4,</span></span><br><span class="line"><span class="string">      "</span>firstN<span class="string">ame": "</span><span class="type">Bertram</span><span class="string">",</span></span><br><span class="line"><span class="string">      "</span>lastN<span class="string">ame": "</span><span class="type">Gilfoyle</span><span class="string">"</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      "</span><span class="string">id": 5,</span></span><br><span class="line"><span class="string">      "</span>firstN<span class="string">ame": "</span><span class="type">Erlich</span><span class="string">",</span></span><br><span class="line"><span class="string">      "</span>lastN<span class="string">ame": "</span><span class="type">Bachman</span><span class="string">"</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> piedPier = piedPierJSON.extract[<span class="type">Company</span>]</span><br></pre></td></tr></table></figure><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>I find json4s to be a pleasure to work with because of its simplicity and powerful features. I think it could be a good go-to choice for Scala JSON serialization/deserialization, unless you are not using the Play Framework (Play has its own utilities to work with JSON and I am saving it for a later post).</p><p>As always, I would really appreciate your thoughts/comments. Feel free to leave them following this post or tweet me <a href="http://twitter.com/home?status=@_LeiG" target="_blank" rel="noopener">@_LeiG</a>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;JSON is a widely used protocol for communication between services. Recently, I was tasked to write some serialization/deserialization log
      
    
    </summary>
    
    
      <category term="scala" scheme="https://www.commitlogs.com/tags/scala/"/>
    
      <category term="json" scheme="https://www.commitlogs.com/tags/json/"/>
    
      <category term="json4s" scheme="https://www.commitlogs.com/tags/json4s/"/>
    
      <category term="serialize" scheme="https://www.commitlogs.com/tags/serialize/"/>
    
      <category term="deserialize" scheme="https://www.commitlogs.com/tags/deserialize/"/>
    
  </entry>
  
  <entry>
    <title>Set Up Blog Like A Pro With AddThis, Cloudflare and Mailgun</title>
    <link href="https://www.commitlogs.com/2017/01/07/set-up-blog-like-a-pro-with-addthis-cloudflare-and-mailgun/"/>
    <id>https://www.commitlogs.com/2017/01/07/set-up-blog-like-a-pro-with-addthis-cloudflare-and-mailgun/</id>
    <published>2017-01-07T18:39:20.000Z</published>
    <updated>2017-01-09T15:40:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>It’s been a few month since I first set up my blog using Hexo and Github Page (more details are in an earlier post <a href="https://commitlogs.com/2016/09/03/how-to-build-blog-with-hexo/" target="_blank" rel="noopener">How To Build A Blog With Hexo On Github Page</a>). As a bonus for myself updating a new post every week, I decided to upgrade my blog with more features. It is an experiment to learn how the SaaS ecosystem is structrued around blogging community. In this post, I am going to introduce some of the handy SaaS solutions out there with freemium plans and walk through a few how-to’s.</p><h2 id="Share-content-across-media-channels"><a href="#Share-content-across-media-channels" class="headerlink" title="Share content across media channels"></a>Share content across media channels</h2><p>RSS is still alive,  but apparently it is no longer the dominant way people keep up with blog updates. Social media is the new norm for content sharing. To get your message out to a big and engaged audience, you should start to maintain some social media presence (most likely you already had it anyways) and make your site share-friendly.</p><h3 id="Integrate-AddThis"><a href="#Integrate-AddThis" class="headerlink" title="Integrate AddThis"></a>Integrate AddThis</h3><p>AddThis makes it easy for readers to share articles to multiple social media sites. You have probably seen it from other sites already, but it provides a sharing bar so that, with a single click, readers are able to share contents to their favorite social media channels. Its freemium version comes with basic analytic tools and simple HTML snippets to be added to your website. You can even configure the basic design, both for desktop and mobile, of the sharing bar.</p><p>After the initial setup, it is just a matter of copy/paste the generated HTML code into the <code>&lt;body&gt;&lt;/body&gt;</code> of your website.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Go to www.addthis.com/dashboard to customize your tools --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"//s7.addthis.com/js/300/addthis_widget.js#pubid=ENTER-YOUR-ADDTHIS-ID"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>And walla! you would have a beautifully designed sharing bar like the one on the right side (or bottom, if you are on mobile) of this post on your own blog. Want to test it out? You could try to share this post to your social network via my sharing bar ;-).</p><h3 id="Enable-rich-content"><a href="#Enable-rich-content" class="headerlink" title="Enable rich content"></a>Enable rich content</h3><p>Now that your readers can share your blog posts easily, you probably want to optimize how the others see the shared content. And the end of the day, a better formatted content helps to improve your click through rate (CTR). Luckily, there is the <a href="http://ogp.me" target="_blank" rel="noopener">Open Graph protocol</a>. To enables any web page to become a rich object in a social graph via Open Graph, you need to add some <code>meta</code> tags to the <code>&lt;head&gt;&lt;/head&gt;</code> of your pages.</p><p>More details can be found on its website, but there are four required tags.</p><ul><li><code>og:title</code> - The title of your object as it should appear within the graph, e.g., “The Rock”.</li><li><code>og:type</code> - The type of your object, e.g., “video.movie”. Depending on the type you specify, other properties may also be required.</li><li><code>og:image</code> - An image URL which should represent your object within the graph.</li><li><code>og:url</code> - The canonical URL of your object that will be used as its permanent ID in the graph, e.g., “<a href="http://www.imdb.com/title/tt0117500/" target="_blank" rel="noopener">http://www.imdb.com/title/tt0117500/</a>“.</li></ul><h2 id="Switch-to-HTTPS-with-Cloudflare"><a href="#Switch-to-HTTPS-with-Cloudflare" class="headerlink" title="Switch to HTTPS with Cloudflare"></a>Switch to HTTPS with Cloudflare</h2><p><code>HTTPS</code> is a protocol for secure communication over network, which provides authentication of the websites being communicated. It is especially useful for websites that involve sensitive information, such as login and payment. But there is a general push for secured communication for all websites. Most famously, Google uses <a href="https://webmasters.googleblog.com/2014/08/https-as-ranking-signal.html" target="_blank" rel="noopener">HTTPS as a ranking signal</a> in its algorithm, which, by itself along, is enough reason for anyone to adopt the HTTPS protocol.</p><p>You can pay a few bucks and get a paid SSL certificate that provides end to end encryption, but I decided to go with the free SSL certificate from Cloudflare since I am pretty sure my static blog is safe ;-).</p><p>To get that green lock on my address bar, I first follow this <a href="https://www.namecheap.com/support/knowledgebase/article.aspx/9607/2210/how-to-set-up-dns-records-for-your-domain-in-cloudflare-account" target="_blank" rel="noopener">tutorial</a> to switch my nameserver from Namecheap to Cloudflare (this step could take up to 24 hours for verification).</p><p>And, a few code snippets need to be added to fully enable HTTPS for the site.</p><p>In <code>config.yml</code> add these so that the static contents are served over the HTTPS version.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">url:</span> <span class="attr">https://www.commitlogs.com</span></span><br><span class="line"><span class="attr">enforce_ssl:</span> <span class="string">www.commitlogs.com</span></span><br></pre></td></tr></table></figure><p>In <code>&lt;head&gt;&lt;/head&gt;</code>, set up canonical link tag so that search engine know to serve the HTTPS version of the site and also redirect users from HTTP version to the HTTPS version.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"canonical"</span> <span class="attr">href</span>=<span class="string">" &#123; &#123; site.url &#125; &#125;&#123; &#123; page.url &#125; &#125;"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> host = <span class="string">"commitlogs.com"</span>;</span></span><br><span class="line"><span class="javascript">    <span class="keyword">if</span> ((host == <span class="built_in">window</span>.location.host) &amp;&amp; (<span class="built_in">window</span>.location.protocol != <span class="string">"https:"</span>))</span></span><br><span class="line"><span class="javascript">        <span class="built_in">window</span>.location.protocol = <span class="string">"https"</span>;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Use-domain-specific-email-address-with-Mailgun"><a href="#Use-domain-specific-email-address-with-Mailgun" class="headerlink" title="Use domain specific email address with Mailgun"></a>Use domain specific email address with Mailgun</h2><p>Ever wondering how that cool kid gets his own email domain name? Guess what, you already had one when you registered your domain name. Depending on your nameserver, any domain name comes with unlimited email forwarding and some number of email sending support for free (you can always pay to get more).</p><p>The reason I am using Mailgun is that it provides email sending capability by the number of emails sent per month, not by number of email addresses. And, since I am using Cloudflare for free SSL certificate, I lose the free email sending service from my nameserver. Plus, the setup for Mailgun is super easy that you just need to make a few changes with your DNS provider, not even a line of code for your website. Here is a good <a href="https://medium.com/@ustcboulder/setup-mailgun-on-namecheap-spf-dkim-cname-and-mx-684b5c1fb492#.pajo6hrcz" target="_blank" rel="noopener">tutorial</a> if you are lazy to google it out.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Alright, hope you enjoyed this post from the upgraded version of <a href="https://commitlogs.com" target="_blank" rel="noopener">commitlogs.com</a>. I think these SaaS are very handy and can get you a better start on your blogging journey. But, I want to call out the following quote from a successful man, since the only way to get your blog going is to keep blogging.</p><blockquote><p>Content is king.</p><p align="right">— Bill Gates</p></blockquote><p>As always, I would really appreciate your thoughts/comments. Feel free to leave them following this post or tweet me <a href="http://twitter.com/home?status=@_LeiG" target="_blank" rel="noopener">@_LeiG</a>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;It’s been a few month since I first set up my blog using Hexo and Github Page (more details are in an earlier post &lt;a href=&quot;https://commi
      
    
    </summary>
    
    
      <category term="blog" scheme="https://www.commitlogs.com/tags/blog/"/>
    
      <category term="saas" scheme="https://www.commitlogs.com/tags/saas/"/>
    
      <category term="html" scheme="https://www.commitlogs.com/tags/html/"/>
    
      <category term="https" scheme="https://www.commitlogs.com/tags/https/"/>
    
      <category term="addthis" scheme="https://www.commitlogs.com/tags/addthis/"/>
    
      <category term="cloudflare" scheme="https://www.commitlogs.com/tags/cloudflare/"/>
    
      <category term="mailgun" scheme="https://www.commitlogs.com/tags/mailgun/"/>
    
  </entry>
  
  <entry>
    <title>Always Learning, But Never For The Sake Of It</title>
    <link href="https://www.commitlogs.com/2016/12/31/always-learning-but-never-for-the-sake-of-it/"/>
    <id>https://www.commitlogs.com/2016/12/31/always-learning-but-never-for-the-sake-of-it/</id>
    <published>2017-01-01T01:10:50.000Z</published>
    <updated>2017-01-02T05:10:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>Are you someone who is highly motivated, always keen to learn new skills, but not feeling particularly accomplished on a day-to-day basis or, even worse, consistently anxious about missing some buzz words from Hacker News?</p><p>Read on. You seriously need changes.</p><h2 id="Learner’s-Symptom"><a href="#Learner’s-Symptom" class="headerlink" title="Learner’s Symptom"></a>Learner’s Symptom</h2><p>I felt exactly the same way and I came to realize these characteristics actually characterize, what I’d like to call, the Learner’s Symptom.</p><p>Been in the tech industry, everything is moving super fast with new programming languages, frameworks and tools being developed almost everyday. Take the notorious Javascript community for example. If you were able to follow along (that’s a BIG “if”), you probably have learnt more frameworks than the number of actual projects you have built, excluding those todo list toy projects. Chances are that you come a long way from BackboneJS, to AngularJS 1, to VueJS, to AngularJS 2, to ReatJS and to the next big thing, whatever that might be. Actually, you could check out this post <a href="https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f#.thshikg3v" target="_blank" rel="noopener">How it feels to learn JavaScript in 2016</a> for a perfect illustration. Moreover, with the full-stack developer and dev/ops movements, you probably get brain fucked by merely keeping up with all those nouns in the field.</p><p>There are literally thousands of things to master in software development. </p><p>And it takes 10,000 hours of “deliberate practice” to master any one of them. Well, that might be a little exaggerated, but you get the idea.</p><p>As a learner, or, better, lifelong learner as you like to call yourself, you enjoy learning new knowledge and you always hop onto the new things. You read Hacker News everyday and subscribe to Twitter List of programming thought leaders. Your New Year’s resolution probably is to learn X languages or frameworks. You spend most of your spare time working through tutorials or watching online lessons.</p><p>And, that’s all good. It demonstrates your passion and persistence. I admire that.</p><p>But, that’s not the most effective way of learning. Because, you are most likely learning for the sake of learning. Learning things this way, you are probably just scratching surfaces here and there. Moreover, you are consistently at the risk of burning out. Your biggest accomplishments could only be having learnt X languages/frameworks.</p><p>Unfortunately, you might have the Learner’s Symptom.</p><h2 id="Goal-oriented-learning"><a href="#Goal-oriented-learning" class="headerlink" title="Goal-oriented learning"></a>Goal-oriented learning</h2><p>Why have I got the Learner’s Symptom, you might ask? I think it is because 1) you are self-motivated to get better, but 2) you lack a clear end goal.</p><p>The logic goes like this: you are very motivated so that you are constantly learning new things that you think could be helpful to your success. But, because you don’t have a clear goal or definition of “succuess”, it is unlikely you would have a clear path to it. That means, you don’t actually know which skills or knowledge are helpful. Well, what would you do as a self-motivated person? You set out to learn them all! That is, you learn for the sake of learning.</p><p>To not learn for the sake of learning, I would suggest you to adopt goal-oriented learning. That means, you should always set clear median-term goals, which should be specific, measurable and attainable. “Be an awesome developer” could be a long-term vision, but that might not be much helpful to define a clear path to get there. Instead, you should break that vision down to clear goals, such as “learn full-stack skills by building a blog app with the MEAN stack” and “deploy an web app to AWS and scale it to 10X traffic”.</p><p>More practically, I find it is very useful to append a goal with a comprehensive project. I am not talking about those toy projects bundled with tutorials (don’t get me wrong, toy projects are great to learn specific techniques), but a full-fledged one. A serious project would likely to expose you to a lot more challenges. Many of them are beyond the scope of a specific technology, but are essential to your overall capability as a developer. As a bonus point, it is just a rewarding experience to actually ship something to the Wild West World (www), a.k.a. the internet.</p><p>Speaking from personal experience, by embracing goal-oriented learning, I started to work on projects with more purpose. I find myself becoming more effective because I need to prioritize my time to best achieve my goal. That often means actually ship a project, instead of spending time purposelessly going through online tutorials.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Learning is good. In fact, I am all for lifelong learning, but I would urge you to learn with a specific goal in mind. Never learn for the sake of learning. You should master the skill of learning and always use it to serve as means to reach your goal. At the end of the day, learning is not your goal; it merely is a tool to get you there.</p><p>I would really appreciate your thoughts/comments here. Feel free to leave them following this post or tweet me <a href="http://twitter.com/home?status=@_LeiG" target="_blank" rel="noopener">@_LeiG</a>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Are you someone who is highly motivated, always keen to learn new skills, but not feeling particularly accomplished on a day-to-day basis
      
    
    </summary>
    
    
      <category term="learning" scheme="https://www.commitlogs.com/tags/learning/"/>
    
      <category term="growth" scheme="https://www.commitlogs.com/tags/growth/"/>
    
      <category term="goal" scheme="https://www.commitlogs.com/tags/goal/"/>
    
  </entry>
  
  <entry>
    <title>Yearly Retrospective 2016</title>
    <link href="https://www.commitlogs.com/2016/12/24/yearly-retrospective-2016/"/>
    <id>https://www.commitlogs.com/2016/12/24/yearly-retrospective-2016/</id>
    <published>2016-12-24T18:58:29.000Z</published>
    <updated>2016-12-26T22:17:33.000Z</updated>
    
    <content type="html"><![CDATA[<p>Yep, you guessed it right. This is one of those retrospective articles flying all over the Internet at the end of the year. But, what’s a better timing than now to look back and learn from the past, or, more importantly, to look forward and plan the next big one?</p><p>2016 is an exciting year for me both professionally and personally. </p><p>Professionally, Steve Jobs’ famous quote from the 2005 Stanford Commencement has always been inspiring to me, and I think I finally have found what I love to work on this year. It took some years and detours, but the feeling is truly amazing and my motivation is at all-time high. </p><blockquote><p>You’ve got to find what you love. And that is as true for your work as it is for your lovers. Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work. And the only way to do great work is to love what you do. If you haven’t found it yet, keep looking. Don’t settle. As with all matters of the heart, you’ll know when you find it. And, like any great relationship, it just gets better and better as the years roll on. So keep looking until you find it. Don’t settle.</p></blockquote><p>Personally, I have became a father in November. Crazy crazy experience and I have been enjoying every little moment with my daughter. I can’t wait to look at the world in a fresh new way and learn many things through the eyes of a baby.</p><p>Alright, I think it’s time for some serious reflections.</p><h2 id="LoveIt"><a href="#LoveIt" class="headerlink" title="LoveIt"></a>LoveIt</h2><ul><li><p>Feel comfortable stepping out of my comfort zone. As a trained data scientist, writing production code wasn’t my expertise and Scala/Spark was completely new to me, but I took up the challenge anyways and was able to deliver effectively. It’s always a bit shocking to me that not everyone is willing to get out of their comfort zone, because I value challenges like this great opportunity for personal growth. It is almost like someone pay you to learn. Where to find better deals than these? More importantly, it almost always opens new doors for you. Some of the challenges may change your life for good. In my case, because of it, I fell in love with building things and got to actually work as a developer. This experience was an “aha” moment in my life and I think I’ve found what I truly enjoyed doing. Would I find it anyways without taking up this challenge? Possibly. But it would probably be much later.</p></li><li><p>Be able to execute consistently. There is a saying in the Valley: “Ideas are cheap; execution is the key.” I think consistent execution is the true differentiator. Although there still is more room for improvement, I did a much better job than previous years on this one. The idea of starting a blog has been with me for quite some time and I attempted a few times in the past, but this is the first time that I am able to actively maintain one at <a href="https://commitlogs.com" target="_blank" rel="noopener">commitlogs.com</a>. Besides this, I was also able to execute at work by delivering machine learning models and A/B testing infrastructures to production, and started a little side project (still at early stage, more on it in a separate post). </p></li><li><p>Figure out techniques to effectively plan and use time. This one has historically been my weakness. With severe procrastination, most of my time was spending at, guess what, thinking about doing something. This year, I have finally come up with some useful time management tactics. It’s a combination of todo list and Pomodoro technique. Every Sunday, I will compile a list of todos for the week arranged by day. For each day, my goal is to finish 8 Pomodoros worth of tasks. Apparently, not everyday is perfect, so I will revise the todo list at the end of each day to reprioritize tasks for the rest of the week. This way, I don’t need to spend energy to think about which tasks to work on during the day and can just use Pomodoro technique to go through the list effectively. Gradually, I have a much better understanding of how my time is spent and learn to estimate time for each task for better prioritization.</p></li></ul><h2 id="CouldBeBetter"><a href="#CouldBeBetter" class="headerlink" title="CouldBeBetter"></a>CouldBeBetter</h2><ul><li><p>Communicate openly and effectively. I am in a pretty wired situation, while my micro-communication skills are not actually that bad, i.e. explain something to others,  my overall communication strategy continues to be a pain point. Specifically, it seems that I tend to shy away from hard conversations. My courage of confronting with people and standing up for what I believe is the right thing to do needs some more fuel. I almost feel like I’m too soft and “easygoing”. I believe one needs to be able to speak up for what he believes and spark a meaningful discussion among shareholders.</p></li><li><p>Stick to a planned life style. There is a theory that any habits take at least 21 days to form. I attempted to foster some good habits using this technique with some success, e.g. I am now reading and practicing guitar pretty regularly. But, when it comes to life style habits, I failed consistently. Specifically, I have most difficulties in getting up from and going to bed on time. I think every strong man should at least has the power to control his own life style. </p></li></ul><h2 id="Development-focus"><a href="#Development-focus" class="headerlink" title="Development focus"></a>Development focus</h2><ul><li><p>Execute consistently. This continues to be the development focus for 2017 as I believe execution is the key to everything. If you do the math, 1.0 X 1.01^(365) = 37.8, every little step counts as long as you are consistent.A practical goal is consistently develop technical skills around building things  by actually building them.</p></li><li><p>Form good lifestyle habits. One needs to have the power to have control over one’s own life; otherwise, how could you expect him to have power over anything else? There are a couple of things, but I’d like to call one thing out. That is, getting up at 5:00am everyday. I come to appreciate the morning time, since it seems to be the most high quality, uninterrupted time of a day. That also means, I should be able to get the most important stuff done during that time, but that’s all under the assumption that I can get up early in the morning.</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Yep, you guessed it right. This is one of those retrospective articles flying all over the Internet at the end of the year. But, what’s a
      
    
    </summary>
    
    
      <category term="retrospective" scheme="https://www.commitlogs.com/tags/retrospective/"/>
    
  </entry>
  
  <entry>
    <title>Predictive Model System - Some Missing Components</title>
    <link href="https://www.commitlogs.com/2016/12/17/predictive-model-deployment-missing-components/"/>
    <id>https://www.commitlogs.com/2016/12/17/predictive-model-deployment-missing-components/</id>
    <published>2016-12-17T21:30:48.000Z</published>
    <updated>2016-12-23T09:59:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>In an earlier post, I talked about <a href="http://commitlogs.com/2016/11/19/predictive-model-deployment-with-spark/" target="_blank" rel="noopener">predictive model deployment with Spark</a>. That post mainly addresses the issues around how to persist a trained model and serve it online in real-time to users. However, there are many other concerns when one set out to build a predictive model system, especially around the robustness and reliability of the system, since predictive models can go terribly wrong without a single error message in the log.</p><p>In this post, I am going to discuss, what I’d like to call, the “continuous deployment” aspects of the predictive model system. Specifically, the “test suites”, i.e., the offline evaluation and A/B testing components around model performance, and monitoring/alerting components around feature generation and model validity.</p><h2 id="Offline-evaluation-and-A-B-testing"><a href="#Offline-evaluation-and-A-B-testing" class="headerlink" title="Offline evaluation and A/B testing"></a>Offline evaluation and A/B testing</h2><p>The concepts of offline evaluation and A/B testing shouldn’t be new to most people with some modeling background, since they both are widely adopted techniques. Here I am going to focus on how/why they are incoporated into a predictive model system.</p><p>I would compare the offline evaluation and A/B testing components in a predictive model system with the tests (e.g., unit test, integration test, or whatever test) in a general software system, simply because they both need to be run/pass before a model can be actually deployed to production.</p><p>A simplified model deployment checklist is:</p><ol><li>model development</li><li>offline evaluation w.r.t. model performance</li><li>A/B testing w.r.t. business metrics</li><li>pick the best model</li><li>model deployment</li></ol><p>The offline evaluation is consisted of some performance scores, e.g., AUC and/or F1 score, that needs to pass certain threshold. These scores are calculated off the training/test dataset and serve as an approximate evaluation of the true model performance. It is not as accurate as A/B testing, but it speeds up development iterations significantly, since an A/B test usually takes days to see a significant result if any. I would recommend set a relatively loose threshold for offline evaluation to filter out the obvious losers and pass a set of “good” models to A/B testing.</p><p>The A/B testing serves as the gate keeper by running two or more models simultaneously. It evaluates a model performance with true users based on business metrics. In most cases, one would expect the A/B testing results to be consistent with the offline evaluation scores. That is, a better offline evaluated model would win in A/B testing. However, there are times the results are different. In those cases, we should, of course, trust the A/B testing result, but one should also take a step back to think about the reasons behind this discrepancy. My experience tells me that, in those cases, there likely to be something pretty informative to improve the next verison of the model.</p><p>These two “tests” help to foster a relative fast model iteration speed and ensure a true model improvement. They are both important steps to achieve an automated deployment with confidence.</p><h2 id="Monitoring-and-alerting"><a href="#Monitoring-and-alerting" class="headerlink" title="Monitoring and alerting"></a>Monitoring and alerting</h2><p>In general, good monitoring/alerting setups help to identify possible defects in a system and analyze root cause when things go wrong. For predictive model system, they are arguably more critical and need to be set up with more components than the typical ones for websites. That is, besides the monitoring/alerting on processing time, responsiveness and uptime, we need tracking systems in place for feature generation and model performance.</p><p>In a predictive model system, features are usually either generated by periodic offline jobs or read directly from production database (see <a href="http://commitlogs.com/2016/11/19/predictive-model-deployment-with-spark/" target="_blank" rel="noopener">this post</a>). All deployed models are trained based on training data at the time of model fitting. Therefore, for models to perform properly, the distribution of feature values should be consistent between training data and production data. This seems to be a safe assumption, since, in theory, training data is just a sample of today’s production data. However, in the real-world, there are at least two ways things could go wrong under your nose.</p><p>For one possibility, the feature generation jobs may produce erroneous results. It may be due to bugs in the job itself or from upstream data sources. This type of error is close to errors in any software system and we could use similar approaches to set up monitoring/alerting. In addition, it is also helpful to track basic statistics of feature values such as mean, median and variance in case any less obvious things are off (I ran into an instance where all features are generated as 0’s without triggering the failed job alert since the job ran “successfully” with erroneous numerical calculations).</p><p>Another possibility is the feature distribution itself may change significantly over time. This could be caused by user behavioral changes led by product changes or other macro changes not directly related to the model itself. Because there is no error per se in such cases, this type of distributional changes is much harder to detect, let alone fix, but it will inevitably compromise the model performance. To catch these unexpected changes, we could try using basic statistics tacking for feature values and/or monitor the model performance online to make sure it is reasonably. In order to evaluate online model performance, a separate offline job is likely needed to gather predicted values versus true outcomes, and compute model performance using the same offline evaluation metrics. The computed metrics is then persisted somewhere in a time-series fashion and used for monitoring/alerting.</p><p>With these addtional monitoring/alerting components, one would be more confident in an automated predictive model system and sleep better at night, if not paged by the alerts ;-).</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><blockquote><p>Automation comes with the risk of breaking things.</p></blockquote><p>In this post, I attempted to cover a few components for building reliable predictive model systems and I hope you would find it helpful. Since I just started out to build this type of systems, I am sure there are many pieces that are still missing.</p><p>I would really appreciate your thoughts/comments here. Feel free to leave them following this post or tweet me <a href="http://twitter.com/home?status=@_LeiG" target="_blank" rel="noopener">@_LeiG</a>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;In an earlier post, I talked about &lt;a href=&quot;http://commitlogs.com/2016/11/19/predictive-model-deployment-with-spark/&quot; target=&quot;_blank&quot; rel
      
    
    </summary>
    
    
      <category term="deployment" scheme="https://www.commitlogs.com/tags/deployment/"/>
    
      <category term="machine learning" scheme="https://www.commitlogs.com/tags/machine-learning/"/>
    
      <category term="offline evaluation" scheme="https://www.commitlogs.com/tags/offline-evaluation/"/>
    
      <category term="ab testing" scheme="https://www.commitlogs.com/tags/ab-testing/"/>
    
      <category term="monitoring" scheme="https://www.commitlogs.com/tags/monitoring/"/>
    
      <category term="alerting" scheme="https://www.commitlogs.com/tags/alerting/"/>
    
  </entry>
  
  <entry>
    <title>Basic Middleware in ExpressJS</title>
    <link href="https://www.commitlogs.com/2016/12/10/basic-middleware-in-expressjs/"/>
    <id>https://www.commitlogs.com/2016/12/10/basic-middleware-in-expressjs/</id>
    <published>2016-12-10T17:00:16.000Z</published>
    <updated>2016-12-12T17:18:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>ExpressJS is an unopinionated, minimalist web framework for NodeJS. Among many others, <strong>middleware</strong> is an important concept to build any ExpressJS applications. Its significance is clear from the following paragraph in the <a href="http://expressjs.com/en/guide/using-middleware.html" target="_blank" rel="noopener">official ExpressJS tutorial</a>,</p><blockquote><p>Express is a routing and middleware web framework that has minimal functionality of its own: An Express application is essentially a series of middleware function calls.</p></blockquote><p>As part of my own learning, we are going to look at a few examples in this post in the hope to understand how middleware functions</p><ul><li>execute any code</li><li>make changes to the request and the response objects</li><li>end the request-response cycle</li><li>call the next middleware function in the stack</li></ul><p>Note that I borrow many examples from this awesome book <a href="https://www.amazon.com/Web-Development-Node-Express-Leveraging/dp/1491949309/ref=sr_1_1?ie=UTF8&amp;qid=1481416857&amp;sr=8-1&amp;keywords=web+development+with+node+express" target="_blank" rel="noopener">Web Development with Node &amp; Express</a> by <a href="https://twitter.com/EthanRBrown" target="_blank" rel="noopener">@EthanRBrown</a> and you could find more interesting stuff from the book.</p><h2 id="The-absolute-basics"><a href="#The-absolute-basics" class="headerlink" title="The absolute basics"></a>The absolute basics</h2><p>Most of the middleware functions take three parameters <code>req</code> (a request object), <code>res</code>(a response object) and <code>next</code> (the next middleware function), although some have the additional <code>err</code> parameter for error handling. And these functions are executed in a pipeline, i.e. ordered, fashion. Middleware functions can be inserted into the pipeline by calling <code>app.use()</code> and passed by calling <code>next()</code>.</p><p>The usual route handler <code>app.VERB</code> is a special type of middleware that handles specific HTTP verbs, e.g. <code>GET</code>, <code>POST</code>, etc and it requires a path as its first parameter.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> app = <span class="built_in">require</span>(<span class="string">'express'</span>)</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">'/'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>)) </span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/: route terminated'</span>);</span><br><span class="line">res.send(<span class="string">'homepage'</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">'/'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>)) </span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/: never called'</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>In the above example, the request terminates with the first route handler. Suppose we rewrite the first route handler with a <code>next()</code> function, the request will be passed onto the next handler. Note that, if a middleware doesn’t call <code>next()</code>, it would terminate a request and it should always send something to the client; otherwise, the client would hang and eventually timeout. On the other side, when there is a <code>next()</code>, nothing should be sent to the client at the moment.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> app = <span class="built_in">require</span>(<span class="string">'express'</span>)</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">'/'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res, next</span>)) </span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/: route not terminated'</span>);</span><br><span class="line">next();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">'/'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res, next</span>)) </span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/: always called'</span>);</span><br><span class="line">res.send(<span class="string">'homepage'</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">'/'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res, next</span>)) </span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/: never called'</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>Similarly, a middleware function can be thought as a route handler that handles all HTTP request and, thus, it doesn’t need a path parameter. We could replace some of the above route handlers with middleware functions, but the results would change accordingly.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> app = <span class="built_in">require</span>(<span class="string">'express'</span>)</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">'/'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res, next</span>)) </span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/: route not terminated'</span>);</span><br><span class="line">next();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.use(<span class="function"><span class="keyword">function</span>(<span class="params">req, res, next</span>)) </span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'always called'</span>);</span><br><span class="line">res.send(<span class="string">'could be any pages'</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.use(<span class="function"><span class="keyword">function</span>(<span class="params">req, res, next</span>)) </span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'never called'</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>Admittedly, this is not a particularly interesting example, but note how the results change because middleware doesn’t have a specified path. Also, this is not a typical use of middleware functions. Instead, there is a commom pratice to have a “catch-all” middleware function as the very last one that returns a status code 404 (Not Found).</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> app = <span class="built_in">require</span>(<span class="string">'express'</span>)</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">'/'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res, next</span>)) </span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/: route terminated'</span>);</span><br><span class="line">res.send(<span class="string">'homepage'</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.use(<span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>)) </span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'route not handled'</span>);</span><br><span class="line">res.send(<span class="string">'404 - Not Found'</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h2 id="The-not-so-basic-basics"><a href="#The-not-so-basic-basics" class="headerlink" title="The not-so-basic basics"></a>The not-so-basic basics</h2><p>The pipeline logic of route handlers and middleware functions should be pretty clear in the above examples, but things may get a bit tricky in the real world when there are many route handlers and middleware functions nested together. The logic stays the same, but it would need extra care to make sure users can access the right content.</p><p>To make my point, I am borrowing an example from <a href="https://twitter.com/EthanRBrown" target="_blank" rel="noopener">@EthanRBrown</a>‘s book as a simplified version of the real world. You should be able to walk through it with the described logic as long as you look closely.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> app = <span class="built_in">require</span>(<span class="string">'express'</span>)</span><br><span class="line"></span><br><span class="line">app.use(<span class="function"><span class="keyword">function</span>(<span class="params">req, res, next</span>)</span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'\n\nALLWAYS'</span>);</span><br><span class="line">next();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">'/a'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>)</span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/a: route terminated'</span>);</span><br><span class="line">res.send(<span class="string">'a'</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">'/a'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>)</span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/a: never called'</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">'/b'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res, next</span>)</span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/b: route not terminated'</span>);</span><br><span class="line">next();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.use(<span class="function"><span class="keyword">function</span>(<span class="params">req, res, next</span>)</span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'SOMETIMES'</span>);</span><br><span class="line">next();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">'/b'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">req, res, next</span>)</span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/b (part 2): error thrown'</span> );</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> <span class="built_in">Error</span>(<span class="string">'b failed'</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.use(<span class="string">'/b'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">err, req, res, next</span>)</span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/b error detected and passed on'</span>);</span><br><span class="line">next(err);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">'/c'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">err, req</span>)</span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/c: error thrown'</span>);</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> <span class="built_in">Error</span>(<span class="string">'c failed'</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.use(<span class="string">'/c'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">err, req, res, next</span>)</span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'/c: error deteccted but not passed on'</span>);</span><br><span class="line">next();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.use(<span class="function"><span class="keyword">function</span>(<span class="params">err, req, res, next</span>)</span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'unhandled error detected: '</span> + err.message);</span><br><span class="line">res.send(<span class="string">'500 - server error'</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.use(<span class="function"><span class="keyword">function</span>(<span class="params">req, res</span>)</span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'route not handled'</span>);</span><br><span class="line">res.send(<span class="string">'404 - not found'</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'listening on 3000'</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>Notice that, if a request goes to <code>\b</code>, the client would see a <code>404</code>, but, if a request goes to <code>\c</code> instead, it would get a <code>500</code>, depending on whether an <code>err</code> is passed to the catch-all middleware.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Hope you get a good grasp of how <strong>middleware</strong> works with ExpressJS. With a large, active community, there are many useful middleware functions being developed and most of the times you don’t need to reinvent the wheel. Although, unfortunately, there currently isn’t an index for all the middleware available, one thing you could try is to search <code>npm</code> for “Express”, “Connect” and “Middleware”.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ExpressJS is an unopinionated, minimalist web framework for NodeJS. Among many others, &lt;strong&gt;middleware&lt;/strong&gt; is an important concep
      
    
    </summary>
    
    
      <category term="javascript" scheme="https://www.commitlogs.com/tags/javascript/"/>
    
      <category term="expressjs" scheme="https://www.commitlogs.com/tags/expressjs/"/>
    
      <category term="nodjs" scheme="https://www.commitlogs.com/tags/nodjs/"/>
    
      <category term="web development" scheme="https://www.commitlogs.com/tags/web-development/"/>
    
  </entry>
  
  <entry>
    <title>Thoughts on David Heinemeier Hansson Interview</title>
    <link href="https://www.commitlogs.com/2016/12/03/thoughts-on-dhh-interview/"/>
    <id>https://www.commitlogs.com/2016/12/03/thoughts-on-dhh-interview/</id>
    <published>2016-12-03T21:42:34.000Z</published>
    <updated>2016-12-05T01:02:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, David Heinemeier Hansson, a.k.a <a href="https://twitter.com/dhh" target="_blank" rel="noopener">@dhh</a>, the creator of the Ruby on Rails web development framework and a successful entrepreneur, was interviewed on the Tim Ferriss Show. I have been following him on Twitter for a while and it was always interesting, sometimes enlightening, to learn his perspective on habit, business and other                                                                         matters. Over the 3-hour show, he touches on many of these aspects and I resonate many with him, so I thought it would be helpful to summarize some of the ideas here for future reference.</p><h2 id="Self-development"><a href="#Self-development" class="headerlink" title="Self development"></a>Self development</h2><p>Conventional wisdom tells us to put our 100% effort into something that we really enjoy doing and strive to be the best on that single thing, e.g. being the Michael Jordan on basketball, but @dhh says something different and he himself wears many hats with great success. As a programmer, he developed the Ruby on Rails framework, which is one of the most widely adopted web development framework; as a entrepreneur, he bootstrapped the company Basecamp (previously known as 37signals) with Jason Fried that has been profitable for more than 10 years; he is also a Le Mans &amp; WEC class-winning race car driver, a hobbyist photographer and a public speaker.</p><p>When asked about how he had accomplished so many, @dhh attributes it to <a href="https://en.wikipedia.org/wiki/Pareto_principle" target="_blank" rel="noopener">the 80/20 rule</a>. The idea is that you can either devote 100% of your effort to be the absolute best in one thing or diverse a little bit to be the top 15% ~ 20% in, let’s say, five things. The latter is also tremendously valuable. With a mix of good skills, your strength can bend and stretch, which is sometimes more important in life.</p><p>I couldn’t agree more on this point and that’s actually how I generally think about self-development as well. I think, if someone has one thing that he/she is willing to devote 100% of his/her life to it, that’s absolutely lucky and he/she should definitely pursue that one thing to the best. However, not everyone is lucky enough to find this one thing that they are willing to give up everything else for; or, arguably, it may not even exist for everyone. For me, I like a couple of things in life and I want to do each one of them well enough (in the top 20% as @dhh puts it). For example, I like programming and making things that people find useful, but I also enjoy playing guitar and spending time with my family. I wouldn’t want to trade one thing for another. So, what I should do is to narrow down those things to a reasonable amount (it’s extremely hard to be in the top 20% for more than 5 things if you calculate the compounding probability) and just stick to them for a long time to get better.</p><p>A practical way to getting better is to get into the flow. It is the key to get you to the top 20%, and it may come easily or through enough practice depending on the nature of the task. Flow generally comes when you work on something you enjoy for an uninterrupted period of time, so it is important to block about 3 hours everyday for deliberate practice on the multipliers, i.e. the most impactful things. To make it more efficient, you should limit yourself to only work 3 hours on it per day to artificially create the sense of urgency, meaning, if you don’t get a good 3 hours, you lose the day of work. With the limited blocked time, you would really achieve the peak of your producivity with best efficiency.</p><h2 id="Self-sufficiency"><a href="#Self-sufficiency" class="headerlink" title="Self sufficiency"></a>Self sufficiency</h2><p>Another notion that @dhh mentions is the so-called self-sufficiency. He came from refusing to learn programming to becoming one of the best programmers all because he doesn’t want to bother people to make things happen for the gaming website he was running. He is motivated by the idea that he should be self sufficient and make things work by himself. This is not all that good in some scenarios, but it drives him to where he is today in the world of programming.</p><p>Be an introvert myself, the power to be self sufficient also motivates me in many ways, most recently on my career change. I started out as a data scientist that analyze data and build predictive models, but, over the time, I find myself constantly dependent on others to actually bring the models I build to customers, because they need to be implemented in production. I felt that part both inefficient and annoying, so I decided to get my hands dirty and write production code myself. Over the months, I jump from like of the outcome to like of the activity itself, i.e. programming. Eventually, I decide to be a professional developer and it just opens up a whole new world to me. I am now enabled to work on my side project as a sole developer to build a product from scratch.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Besides the thoughts mentioned here, I am also really inspired by what @dhh have presented on lifestyle design and his view on how to build a successful business without VC funding. For anyone who is interested in the interview, here is the <a href="http://fourhourworkweek.com/2016/10/27/david-heinemeier-hansson/" target="_blank" rel="noopener">link</a> to the podcast. Hope you would enjoy as well!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Recently, David Heinemeier Hansson, a.k.a &lt;a href=&quot;https://twitter.com/dhh&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;@dhh&lt;/a&gt;, the creator of the R
      
    
    </summary>
    
    
      <category term="technology" scheme="https://www.commitlogs.com/tags/technology/"/>
    
      <category term="random" scheme="https://www.commitlogs.com/tags/random/"/>
    
  </entry>
  
  <entry>
    <title>Some Reflections on Recent Career Change</title>
    <link href="https://www.commitlogs.com/2016/11/26/some-reflections-on-recent-career-change/"/>
    <id>https://www.commitlogs.com/2016/11/26/some-reflections-on-recent-career-change/</id>
    <published>2016-11-26T19:47:41.000Z</published>
    <updated>2016-12-03T21:50:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>My background was primarily pure science with four years in college studying mathematics and another four years in a PhD program doing statistics. Trainings in these two subjects taught me how to think/reason rigorously and mine information out of datasets. Those are valuable skills that I really enjoyed learning. At the same time, I am passionate about the growing tech scene in the Bay Area, mainly because of the fast speed things are moving and the massive impacts an individual can have. With that in mind, I jumped right into the startup world as a data scientist at <a href="https://www.thumbtack.com" target="_blank" rel="noopener">Thumbtack</a> after graduation.</p><p>Time flies and it has been a year since then, I feel this might be a good time to reflect some of the things I noticed from this career change.</p><p>There are the usual consensus. The execution speed in the tech world, where product features are developed and tested continuously, is 10X faster than academia. In academia, the equivalent of shipping products is to publish papers, which is a process often measured in years (truth being told, I still have a paper under review, which was submitted almost a year ago). Similar with direct impact, technology enables products to scale and affect massive users in near real-time, whereas most scientific research only have direct influence on a very small and specialized community of researchers, although they may eventually have a significant impact on our society.</p><p>But, most importantly, I am thrilled to be part of product initiatives where makers of different types working together to build ideas into actual products and ship them to millions of users. The experience of building something from 0 to 1 is just mind-blowing. It feels like drugs - you will get addicted to it in a good way. Although this is all relatively new to me, I am already hooked up to it and I think Albert Einstein explained the reason well.</p><blockquote><p>Scientists investigate that which already is; Engineers create that which has never been.<br>- Albert Einstein</p></blockquote><p>With such experiences, I am now a firm believer that the future belongs to the makers. With the skills and passion, makers can make the world better by delivering their crafts, and technology is enabling them to scale it up and reach a very large audience.</p><p>Looking forward to the next few years, I should just continue to improve my craftsmanship by doing what I love, learning from others and keep making stuff. As Steve Jobs once said,</p><blockquote><p>You can’t connect the dots looking forward; you can only connect them looking backwards. So you have to trust that the dots will somehow connect in your future. You have to trust in something – your gut, destiny, life, karma, whatever. Because believing that the dots will connect down the road will give you the confidence to follow your heart even when it leads you off the well worn path; and that will make all the difference. </p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;My background was primarily pure science with four years in college studying mathematics and another four years in a PhD program doing st
      
    
    </summary>
    
    
      <category term="technology" scheme="https://www.commitlogs.com/tags/technology/"/>
    
      <category term="random" scheme="https://www.commitlogs.com/tags/random/"/>
    
  </entry>
  
  <entry>
    <title>Predictive Model Deployment with Spark</title>
    <link href="https://www.commitlogs.com/2016/11/19/predictive-model-deployment-with-spark/"/>
    <id>https://www.commitlogs.com/2016/11/19/predictive-model-deployment-with-spark/</id>
    <published>2016-11-19T19:10:22.000Z</published>
    <updated>2017-01-01T01:19:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>Predictive models, a.k.a. machine learning models (if you prefer the buzzword), play huge parts in today’s technology companies. They are used to uncover valuable patterns from mass datasets that are just too complicated for humans to consume directly. <a href="http://commitlogs.com/tags/spark/" target="_blank" rel="noopener">Spark</a> is a large-scale data processing engine that handles large datasets efficiently in a distributed way. Given Spark’s already high adoption as the data process engine and its rapid development in machine learning modeling, it is natural for many companies to build its machine learning eco-system around Spark.</p><p>The Spark MLlib library provides an easy-to-use model train/test process that is familiar to data scientists to play around and fine tune predictive models. A pretty standard offline model training process often involves these following steps, which are wrapped into a pipelining type of operations in Spark MLlib (see <a href="http://spark.apache.org/docs/latest/ml-pipeline.html" target="_blank" rel="noopener">examples</a>).</p><ol><li>Load historical data</li><li>Feature extraction/engineering</li><li>Model training</li><li>Model evaluation</li></ol><p>However, deploying predictive model to a production environment, or serving the model in production, is a bit more complicated. Its architecture largely depends on how the model will be used. At very high level, predictive models often are used to score some instances, e.g. the risk score of fraud transaction or the likelihood of clicking on ads. This scoring operation can be offline or online, depending on its application. Offline scoring means the model doesn’t needs to score an instance in real-time and online scoring means the model is required to score with real-time input and low-latency. In this post, I am going to touch on a few common architectures and their use cases.</p><h2 id="Batch-prediction"><a href="#Batch-prediction" class="headerlink" title="Batch prediction"></a>Batch prediction</h2><p>For models used for offline scoring, we can used the batch prediction architecture. That is, we don’t really serve the model online; instead, the actual scoring happens in batches offline and we just need to serve the scores produced by the model online. This architecture can be combined with the offline model training setup because both are in an offline environment. We can directly use Spark MLlib’s model training pipeline to fit a model and then store the predicted scores into a database and let our online service talks to that database to serve the scores.</p><p>This architecture can be summarized as<br><img src="/images/pmdws-batch.jpg" alt=""></p><h2 id="Hard-coded-model"><a href="#Hard-coded-model" class="headerlink" title="Hard-coded model"></a>Hard-coded model</h2><p>For online scoring, we do need to serve the model itself online to respond to incoming signals in real-time. A simply, but effective architecture is to hard code the actual model into your online serving service. This is straightforward for regression based models, such as linear regression and logistic regression. Since the scoring logic of these models can be explicitly coded up easily. At the end of the day, scores from regression based models are just a multiplication of features with its fitted coefficients. Note that the feature generation logic should be the same between offline model training and online scoring. In this case, we just need to store coefficients from offline training into a database so that the online serving service has access to it in order to implement the scoring logic.</p><p>This architecture can be summarized as<br><img src="/images/pmdws-hard.jpg" alt=""></p><h2 id="Model-persistence"><a href="#Model-persistence" class="headerlink" title="Model persistence"></a>Model persistence</h2><p>For more sophisticated model, the hard-coded model logic can get very complicated and error-prone. It is preferred to serve the offline trained model directly to production. Luckily, with latest Spark, we can persistent the trained model/pipeline into a physical storage and then load it back for scoring. This can be easily achieved via the following command.<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// suppose we have a trained RandomForestClassificationModel model</span></span><br><span class="line">trainedModel.save(<span class="string">"s3n://.../trainedModel"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// load the same model back</span></span><br><span class="line"><span class="keyword">val</span> sameTrainedModel =</span><br><span class="line">  <span class="type">RandomForestClassificationModel</span>.load(<span class="string">"s3n://.../trainedModel"</span>)</span><br></pre></td></tr></table></figure></p><p>Internally, the model metadata and parameters are saved as JSON and the data as Parquet. One thing to call out here, in order for this to work, the online service needs to run Spark in local mode; otherwise, it can get a little tricky to load the model back.</p><p>Compared to the architecture of hard-coded model, we directly save the model to storage and load it for scoring. The logic is pretty straightforward and can support more models, although it is not as light-weighted as the previous approach, due to extra requirements on the serving service.</p><p>This architecture is similar to the hard-coded model, but store the trained model directly<br><img src="/images/pmdws-persistence.jpg" alt=""></p><h2 id="Predictive-Model-Markup-Language-PMML"><a href="#Predictive-Model-Markup-Language-PMML" class="headerlink" title="Predictive Model Markup Language (PMML)"></a>Predictive Model Markup Language (PMML)</h2><p>More generally, we can use the Predictive Model Markup Language (PMML) to represent predictive models and communicate it to other language/framework. The idea is similar to how web services talk to each other via a standard protocol such as JSON or Thrift. PMML is the de facto standard language used to represent predictive analytic models. It is based on XML and allows for predictive solutions to be easily shared between PMML compliant applications. Spark supports model export to PMML for a list of models, such as <code>LinearRegressionModel</code>, <code>RidgeRegressionModel</code> and <code>LassoModel</code> (see <a href="https://spark.apache.org/docs/latest/mllib-pmml-model-export.html" target="_blank" rel="noopener">full list</a>). Interestingly though, Spark doesn’t support load model from PMML directly. But the one-way conversion is very easy using the following syntax.<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// suppose we have a trained model</span></span><br><span class="line">trainedModel.toPMML(<span class="string">"/tmp/trainedModel.xml"</span>)</span><br></pre></td></tr></table></figure></p><p>Again, the architecture is very similar to model persistence, since we just use another format to represent the model in storage<br><img src="/images/pmdws-pmml.jpg" alt=""></p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>From prototype to production often involves a whole set of different considerations and trade-offs. Some extra implementation work must be done to make a balance between a fast iterating offline training pipeline and a robust online model serving service. It is great that Spark provides us with different options so that we can leverage them based on our specific use cases.</p><p>Of course, there are other interesting topics around deploying predictive model to production that I am very interested in and will write about later. For example, how do we think about regular model update/re-train and how to leverage our A/B testing framework to automate this process? If you are interested as well, stay tuned (updated: <a href="https://commitlogs.com/2016/12/17/predictive-model-deployment-missing-components/" target="_blank" rel="noopener">Predictive Model System - Some Missing Components</a>)!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Predictive models, a.k.a. machine learning models (if you prefer the buzzword), play huge parts in today’s technology companies. They are
      
    
    </summary>
    
    
      <category term="deployment" scheme="https://www.commitlogs.com/tags/deployment/"/>
    
      <category term="machine learning" scheme="https://www.commitlogs.com/tags/machine-learning/"/>
    
      <category term="spark" scheme="https://www.commitlogs.com/tags/spark/"/>
    
      <category term="batch prediction" scheme="https://www.commitlogs.com/tags/batch-prediction/"/>
    
      <category term="model persistence" scheme="https://www.commitlogs.com/tags/model-persistence/"/>
    
      <category term="pmml" scheme="https://www.commitlogs.com/tags/pmml/"/>
    
  </entry>
  
  <entry>
    <title>Laziness as a Service (LaaS)</title>
    <link href="https://www.commitlogs.com/2016/11/05/laziness-as-a-service/"/>
    <id>https://www.commitlogs.com/2016/11/05/laziness-as-a-service/</id>
    <published>2016-11-06T02:18:36.000Z</published>
    <updated>2016-11-06T23:46:42.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>If necessity is the mother of invention, then laziness is the father.</p></blockquote><p>Recently, I came across a great story behind <a href="http://park.io" target="_blank" rel="noopener">park.io</a>, a service helps you to backorder domain names. At the 1000-feet level, the guy wrote a script that automatically gets any expired domains of interest. Simple idea, right? This company now generates $125K revenue per month with only one employee - the founder himself.</p><p>I bet many people had similar ideas before. We can talk a lot around why ideas are cheap and only execution is the key, but what’s more fascinating to me in this story is how the founder get started with this idea - he wanted to buy a domain name for another of his idea, but was too lazy to check regularly to see when it expires. Instead, as every good engineer would do, he wrote up the initial script to automate this task.</p><p>Good software engineers are lazy. We hate doing mundane tasks. This trait is inherent to us because our job is to do automation. We are constantly looking for opportunities to automate processes, sometimes even ourselves, e.g. the continuous integration/deployment concept. The <strong>DRY</strong> (don’t repeat yourself) rule is such a guiding principle that it is applied widely, ranging from coding, architecture, testing to even documentation.</p><p>Software engineers are empowered to be lazy. We are trained with the skills and, more importantly, the mindset to automate repetitive tasks. But we tend to take this idea of automation for granted and forget that there are huge opportunities here to ease the life of normal people. Besides writing scripts to automate our own tasks, we can build tools to provide <em>Laziness-as-a-Service</em> (<em>Laas</em>) to others and, as people like to put it, make the world a better place. Out of many, Amazon’s <a href="http://amzn.to/2fpQHqC" target="_blank" rel="noopener">Dash Button</a> is a great example that successfully brings a little automation script into everyone’s life. Since its debut in early 2015, it went through rapid growth with more than 150 brands and Dash Button orders now occurring over twice a minute. Simple idea like this provides <em>LaaS</em> to normal people and fundamentally changed the way people live their daily life. In this sense, you don’t have to build the next Google or Tesla to improve the quality of life for everyone.</p><p>Let’s face it - laziness is human nature. There is no point to deny it or to be ashamed. As smart engineers, we should instead use our skills to provide <em>LaaS</em> to help people be lazy and escape from mundane so that they can focus their energy on the creative tasks.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;If necessity is the mother of invention, then laziness is the father.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Recently, I came across a great s
      
    
    </summary>
    
    
      <category term="technology" scheme="https://www.commitlogs.com/tags/technology/"/>
    
      <category term="programming" scheme="https://www.commitlogs.com/tags/programming/"/>
    
  </entry>
  
  <entry>
    <title>A Few Thoughts On Efficient Code Review</title>
    <link href="https://www.commitlogs.com/2016/10/29/few-thoughts-on-effective-code-review/"/>
    <id>https://www.commitlogs.com/2016/10/29/few-thoughts-on-effective-code-review/</id>
    <published>2016-10-30T02:29:45.000Z</published>
    <updated>2016-10-31T16:59:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>Code review is a big part in daily software development here at Valley. Every production change requires at least a +2, ideally from someone who knows the project or the particular part of the codebase well, before it can be merged.</p><p>Code review serves multiple purposes. On a very high level, it helps to</p><ol><li>Enforce high coding standards. </li><li>Find bugs at lower cost.</li><li>Share knowledge between developers.</li></ol><p>With all these benefits, code review comes at the cost of short-term development speed, although it saves time in a long-term perspective. To be frank, it <strong>will</strong> slow down your day-to-day work. This inevitably happens because 1) you need to wait for other people’s availablity and 2) you are not writing the perfect code (let’s agree to disagree on this one).</p><p>So the question becomes - how to make the code review process more efficient? </p><p>As a junior guy, I often find myself on one side of the table, where my code are reviewed by others, so I am eager to make this process more efficient. Over the course, I learnt a few things to make life a bit easier for both reviewers and myself. It would be a lie to say I can stick to these rules every time, but, when I did, they helped to move things faster.</p><h2 id="Test-it-thoroughly"><a href="#Test-it-thoroughly" class="headerlink" title="Test it thoroughly"></a>Test it thoroughly</h2><p>Review broken code is a waste of time for both you and the reviewers. Obvious bugs and compiler errors should already be handled prior to code review, if you had tested thorougly against your development/staging environment. This would save a significant amount of time and build trust between you and the reviewers. At the end of the day, the responsibility is on you to make sure no breaking changes/bugs are introduced. Code reviewers are there to help with their fresh pair of eyes for non-trivial buggy logics that might be hard to detect when look too closely.</p><h2 id="Submit-small-patches"><a href="#Submit-small-patches" class="headerlink" title="Submit small patches"></a>Submit small patches</h2><p>Breaking down changes into small patches not only speeds up the code review process, but also helps with the development process. On the developer side, it forces you to think critically about the structure of your change. Often times, by isolating small pieces of logic out of a large change, your code becomes cleaner and less error-prone with easy testibility. On the reviewers side, a small patch of code is easier to follow and helps to keep their eyes “fresh”. There is the human psychology part as well. People tends to procrastinate on big tasks and it is just much less intimidating to approve a 50 line of change than, say, a 1500 line one.</p><p>The goal of always submitting small patches is to ensure quick turnaround. With quality feedback within a day or two, this wouldn’t block the development of the next patches. Admittedly, things may not go smoothly every time. When the reviewers are delayed for whatever reasons, you may find yourself creating a large stack of small changes with the need of constantly rebasing on top of the previous patches. But, overall, this technique works well from my experience.</p><h2 id="Include-good-commit-message"><a href="#Include-good-commit-message" class="headerlink" title="Include good commit message"></a>Include good commit message</h2><p>Good commit message is the best way to communicate context about a change to fellow developers and reviewers. A commit message includes a subject line and a body. The latter is optional depending on the complexity of the change. The subject line summarizes the change and, if there is a body, it should focus on the what and why parts of the changes, as opposed to how (the code explains that). In this way, your reviewers can quickly get the context and general idea of the change so that they can spend most of their time on the actual code.</p><p>There are seven rules to write a good commit message (I copy&amp;pasted from google). Note that these rules should be treated as code style guide - they should be enforced as part of the code review process. They help to maintain concise and readable commit logs, which is critical to any projects’ long-term success.</p><ol><li>Separate subject from body with a blank line</li><li>Limit the subject line to 50 characters</li><li>Capitalize the subject line</li><li>Do not end the subject line with a period</li><li>Use the imperative mood in the subject line</li><li>Wrap the body at 72 characters</li><li>Use the body to explain what and why vs. how</li></ol><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Like a lot of things, the key to make your reviewers life easier is to put yourself into their shoes. The things outlined here are the ones I would like to see if I were the reviewer. Now, imagine you were in that position, what kinds of code reviews make you happy? Sooner or later, you will be on the other side of the table. So, you might be better off starting to think about this question now and make the changes you would like to see happen.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Code review is a big part in daily software development here at Valley. Every production change requires at least a +2, ideally from some
      
    
    </summary>
    
    
      <category term="code review" scheme="https://www.commitlogs.com/tags/code-review/"/>
    
      <category term="collaboration" scheme="https://www.commitlogs.com/tags/collaboration/"/>
    
  </entry>
  
  <entry>
    <title>Host My Next Side Project - Github vs Gitlab</title>
    <link href="https://www.commitlogs.com/2016/10/22/host-my-next-side-project-github-vs-gitlab/"/>
    <id>https://www.commitlogs.com/2016/10/22/host-my-next-side-project-github-vs-gitlab/</id>
    <published>2016-10-23T03:32:41.000Z</published>
    <updated>2016-10-23T18:25:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>I love working on side projects. They are great opportunities to try out new ideas, technologies and, who knows, they may become something big one day.</p><p>Up till now, I have been hosting most of my side projects on <a href="https://github.com/LeiG" target="_blank" rel="noopener">Github</a>. It has been huge in the open source and enterprise world as de facto <code>git</code> hosting service. But, lately, I came across <a href="https://about.gitlab.com" target="_blank" rel="noopener">Gitlab</a>, which seems to bring the goodies from Github and Bitbucket all together.</p><p>As I am planning my new side project (more on this later :-)), I want to revisit my default and see if Gitlab could actually be a better fit. Omitting the details, here are a couple of things that I think are must-have for this project:</p><ol><li>Private repositories - the project would be a web service instead of some open source tools.</li><li>Continuous deployment - I want to move fast, but don’t want my potential users to experience breaking changes.</li><li>Good project management tools - I like to get things organized and I am huge on those GTD techniques.</li></ol><p>With these in mind, I did a little bit of research on Github and Gitlab.</p><h2 id="Pricing"><a href="#Pricing" class="headerlink" title="Pricing"></a>Pricing</h2><p>Not suprisingly, both Github and Gitlab, or any <code>git</code> hosting services in that matter, have options for private repos. At the end of the day, it is all about how much it costs.</p><ul><li>Github offers a $7/month plan for personal account with unlimited private repos (<a href="https://github.com/pricing" target="_blank" rel="noopener">Github Pricing</a>).</li><li>Gitlab provides unlimited private repos hosted on Gitlab.com for free (<a href="https://about.gitlab.com/pricing/" target="_blank" rel="noopener">Gitlab pricing</a>).</li></ul><p>If you were already a paying user for Github, there is really no additional cost to add more private repos and the comparsion dosen’t really make any sense. That been said, since I am not a paying user today, this one seems to be a no-brainer to me (I agree a few bucks a month isn’t that bad, but I am just a poor guy that thinks every penny matters).</p><h2 id="Continuous-Deployment"><a href="#Continuous-Deployment" class="headerlink" title="Continuous Deployment"></a>Continuous Deployment</h2><p>Continuous Deployment (CD) aims at building, testing, and releasing software faster and more frequently. It is almost the standard for developing web applications nowadays.</p><p>On this front, Github doesn’t provide any support for CD directly, but there are a lot of third party integrations available, e.g. <a href="https://travis-ci.com" target="_blank" rel="noopener">Travis-ci</a>, <a href="https://www.snap-ci.com/my_plans/" target="_blank" rel="noopener">Snap-ci</a> or <a href="https://jenkins.io" target="_blank" rel="noopener">Jenkins</a>. These thrid party tools ranges from open source and free to a fixed subscription fee per month.</p><p>Gitlab offers a built-in CD support, known as <a href="https://about.gitlab.com/gitlab-ci/" target="_blank" rel="noopener">Gitlab-ci</a>, for free with a <a href="https://about.gitlab.com/2016/04/19/gitlab-partners-with-digitalocean-to-make-continuous-integration-faster-safer-and-more-affordable/" target="_blank" rel="noopener">partenership with DigitalOcean</a>. The CD process integrates nicely with Gitlab’s UI and host everything in one place.</p><p>There are definitly more designated and mature CD support out there for Github, given its longer history, more popularity among the open source community and lack of its own implementation. But the big plus for Gitlab to me is that it integrates CD within the platform so that I can have one less extra things to worry about.</p><h2 id="Project-Management-Tools"><a href="#Project-Management-Tools" class="headerlink" title="Project Management Tools"></a>Project Management Tools</h2><p>As a projects grows, there will be more things flowing around and people lose track of them. Thus, I value good project management tools to be important factors to the success of any projects.</p><p>Both Github and Gitlab provides good code review, wiki page and issue tracking tools that are crucial to day-to-day development, but Gitlab supports more features such as associate attachment with issues (very helpful to frontend debugging) and a work-in-progress (/wip) status to avoid accidentally merging unfinished code.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>As you might have already guessed, I am leaning towards using Gitlab for my next side project at this point. It seems to provide more useful features out of the box with less cost. Moreover, isn’t it the spirit of side projects to try out new and shiny things?</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;I love working on side projects. They are great opportunities to try out new ideas, technologies and, who knows, they may become somethin
      
    
    </summary>
    
    
      <category term="side project" scheme="https://www.commitlogs.com/tags/side-project/"/>
    
      <category term="git" scheme="https://www.commitlogs.com/tags/git/"/>
    
      <category term="continuous deployment" scheme="https://www.commitlogs.com/tags/continuous-deployment/"/>
    
      <category term="github" scheme="https://www.commitlogs.com/tags/github/"/>
    
      <category term="gitlab" scheme="https://www.commitlogs.com/tags/gitlab/"/>
    
  </entry>
  
  <entry>
    <title>Spark 2.0 New API - Dataset and its predecessors</title>
    <link href="https://www.commitlogs.com/2016/10/15/spark-2-new-api-dataset-and-its-predecessors/"/>
    <id>https://www.commitlogs.com/2016/10/15/spark-2-new-api-dataset-and-its-predecessors/</id>
    <published>2016-10-15T23:54:20.000Z</published>
    <updated>2016-10-16T22:18:12.000Z</updated>
    
    <content type="html"><![CDATA[<p>Apark Spark, the allegedly hottest open source cluster computing project, recently released a major upgrade to its 2.0 version. With new changes and updates, the performance of its computing engine sees significant improvements.</p><p>To help people get started or transition to this new version, I started <a href="http://commitlogs.com/tags/spark-2-0/" target="_blank" rel="noopener">a series of blog posts</a> to cover Spark 2.0 related stuff. This article in particular talks about one of its major API updates; that is, the introduction of a new interface <code>Dataset</code> (Well, technically, <code>Dataset</code> was introduced in Spark 1.6 as an API preview, but it really becomes stable in this new release). With <code>Dataset</code> and its two predecessors <code>RDD</code> and <code>DataFrame</code>, Spark now has three major APIs for operating large datasets.</p><h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p><code>RDD</code> (<em>Risilient Distributed Dataset</em>) was the primary API introduced since Spark 1.0. It essentially is an immutable distributed collection of elements of your data that is partitioned across nodes in the cluster. It is functional-oriented and emphasizes on immutability, which provides a simple, OOP-style API with complie time type-safety, but may cause issues with garbabge collection due to too many temporary objects being created during computation.</p><p><code>RDD</code> is lazily evaluated. It provides two types of operations, i.e. <em>transformations</em> and <em>actions</em>. The <em>transformations</em>, such as <code>map</code> and <code>reduce</code>, only creates a new <code>RDD</code> representing the transformed data and defines the operations to be performed . The operaions are not actually performed until an <em>action</em> is called. You can find a list of these operations on the <a href="http://spark.apache.org/docs/latest/programming-guide.html#transformations" target="_blank" rel="noopener">Spark Programming Guide</a>.</p><p><code>RDD</code> will continue to be the building block of Spark, since <code>Dataset</code> and <code>DataFrame</code> are built on top of it. It will be the low-level API if you want more explicit control over operations or process unstructured data. But it would not enjoy many of the optimizations and performance benefits available with <code>Dataset</code> and <code>DataFrame</code> due to its lack of structure information and the help brought by Spark’s internal Catalyst Optimizer.</p><h2 id="Dataset-and-DataFrame"><a href="#Dataset-and-DataFrame" class="headerlink" title="Dataset and DataFrame"></a>Dataset and DataFrame</h2><p><code>Dataset</code> is formally introduced in Spark 2.0 and is positioned to take over <code>DataFrame</code> (introduced in Spark 1.3) by bringing in some of the advantages with <code>RDD</code>, such as compile time type-safety. I am combining <code>Dataset</code> and <code>DataFrame</code> here together mainly because <code>DataFrame</code> will merely be an alias for <code>Dataset[Row]</code> starting from Spark 2.0, where <code>Row</code> is a generic untyped object. Alternatively, for a typed object, such as a case class <code>Person</code>, you can create a <code>Dataset[Person]</code>, similar to <code>RDD[Person]</code>, to take advantage of the type-safety.</p><p><code>Dataset</code> optimizes data storage via encoders to eliminate the cost of deserialization and garbabge collection, and improves performance by using Catalyst Optimizer to generate optimized query plan. Its overall performance is improved significantly (see <a href="https://databricks.com/blog/2016/01/04/introducing-apache-spark-datasets.html" target="_blank" rel="noopener">this example</a>). The trade-off here is that <code>Dataset</code> is limited to classes that extend the Scala <code>Product</code> trait, e.g. <code>case class</code>, whereas <code>RDD</code> can be used with any objects.</p><p>Even better, <code>Dataset</code> can be seamlessly convert to <code>RDD</code> by calling the <code>.rdd</code> method.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// suppose you have personDS: Dataset[Person]</span></span><br><span class="line"><span class="keyword">val</span> personRDD: <span class="type">RDD</span>[<span class="type">Person</span>] = personDS.rdd</span><br></pre></td></tr></table></figure><p>And, vice versa, with a little bit extra work, you can also convert <code>RDD</code> to <code>Dataset</code>.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// suppose you have personRDD: RDD[Person] and spark: SparkSession</span></span><br><span class="line"><span class="comment">// implicits is imported to infer type</span></span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> personDS: <span class="type">Dataset</span>[<span class="type">Person</span>] = spark.createDataset[<span class="type">Person</span>](personRDD)</span><br></pre></td></tr></table></figure><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Starting from Spark 2.0, I would imagine <code>Dataset</code> to become de facto API for users to operate with on a daily basis and <code>RDD</code> to be used only when lower level functionality and control are needed. The space efficiency and performance gains with <code>Dataset</code> are very significant for most use cases - at least for me, dealing with structured or semi-structured data is the norm.</p><p>As always, thanks for your time and hope this post is helpful. If you have other Spark 2.0 related questions, you should check out <a href="http://commitlogs.com/tags/spark-2-0/" target="_blank" rel="noopener">this series of posts</a> or leave comments below.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Apark Spark, the allegedly hottest open source cluster computing project, recently released a major upgrade to its 2.0 version. With new 
      
    
    </summary>
    
    
      <category term="scala" scheme="https://www.commitlogs.com/tags/scala/"/>
    
      <category term="spark" scheme="https://www.commitlogs.com/tags/spark/"/>
    
      <category term="spark 2.0" scheme="https://www.commitlogs.com/tags/spark-2-0/"/>
    
      <category term="dataset" scheme="https://www.commitlogs.com/tags/dataset/"/>
    
      <category term="dataframe" scheme="https://www.commitlogs.com/tags/dataframe/"/>
    
      <category term="rdd" scheme="https://www.commitlogs.com/tags/rdd/"/>
    
  </entry>
  
</feed>
